#!/usr/bin/env python3
"""
æ±‡æ€»27ä¸ªç±»åˆ«çš„æ‰©å±•è¯„ä¼°æŒ‡æ ‡
ç”Ÿæˆç»Ÿä¸€çš„åˆ†ææŠ¥å‘Š

è¾“å‡ºï¼š
1. æ‹†åˆ†AUROCæ±‡æ€»è¡¨
2. Marginåˆ†å¸ƒç»Ÿè®¡æ±‡æ€»
3. Semanticè´¡çŒ®æ±‡æ€»
4. å®šæ€§ç»“è®ºæ–‡æ¡£
"""

import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def aggregate_split_auroc():
    """æ±‡æ€»æ‹†åˆ†AUROCç»“æœ"""
    metrics_dir = Path('analysis/extended_metrics')
    all_files = list(metrics_dir.glob('*_split_auroc.csv'))
    
    if not all_files:
        print("âš ï¸  æœªæ‰¾åˆ°æ‹†åˆ†AUROCæ–‡ä»¶")
        return None
    
    dfs = []
    for f in all_files:
        df = pd.read_csv(f)
        dfs.append(df)
    
    combined = pd.concat(dfs, ignore_index=True)
    
    # åˆå¹¶æ€§èƒ½åˆ†ç»„
    performance_data = pd.read_csv('analysis/full_performance_comparison_k2.csv')
    combined = combined.merge(
        performance_data[['class', 'delta_acc', 'performance_group', 'baseline_acc']],
        on='class',
        how='left'
    )
    
    output_path = 'analysis/extended_metrics/split_auroc_summary.csv'
    combined.to_csv(output_path, index=False)
    print(f"âœ… æ‹†åˆ†AUROCæ±‡æ€»: {output_path}")
    
    return combined


def aggregate_margin_stats():
    """æ±‡æ€»Marginç»Ÿè®¡"""
    metrics_dir = Path('analysis/extended_metrics')
    all_files = list(metrics_dir.glob('*_margin_stats.csv'))
    
    if not all_files:
        print("âš ï¸  æœªæ‰¾åˆ°Marginç»Ÿè®¡æ–‡ä»¶")
        return None
    
    dfs = []
    for f in all_files:
        df = pd.read_csv(f)
        dfs.append(df)
    
    combined = pd.concat(dfs, ignore_index=True)
    
    # é€è§†è¡¨ï¼šæ¯ä¸ªç±»åˆ« Ã— ç»„åˆ«
    pivot = combined.pivot_table(
        index='class',
        columns='group',
        values=['mean', 'std', 'median', 'p10', 'p90']
    )
    
    output_path = 'analysis/extended_metrics/margin_stats_summary.csv'
    combined.to_csv(output_path, index=False)
    print(f"âœ… Marginç»Ÿè®¡æ±‡æ€»: {output_path}")
    
    return combined


def aggregate_semantic_contrib():
    """æ±‡æ€»Semanticè´¡çŒ®"""
    metrics_dir = Path('analysis/extended_metrics')
    all_files = list(metrics_dir.glob('*_semantic_contrib.csv'))
    
    if not all_files:
        print("âš ï¸  æœªæ‰¾åˆ°Semanticè´¡çŒ®æ–‡ä»¶")
        return None
    
    dfs = []
    for f in all_files:
        df = pd.read_csv(f)
        dfs.append(df)
    
    combined = pd.concat(dfs, ignore_index=True)
    
    # åˆå¹¶æ€§èƒ½åˆ†ç»„
    performance_data = pd.read_csv('analysis/full_performance_comparison_k2.csv')
    combined = combined.merge(
        performance_data[['class', 'delta_acc', 'performance_group', 'baseline_acc']],
        on='class',
        how='left'
    )
    
    output_path = 'analysis/extended_metrics/semantic_contrib_summary.csv'
    combined.to_csv(output_path, index=False)
    print(f"âœ… Semanticè´¡çŒ®æ±‡æ€»: {output_path}")
    
    return combined


def analyze_split_auroc(df):
    """åˆ†ææ‹†åˆ†AUROCç»“æœ"""
    print("\n" + "="*80)
    print("ã€ä»»åŠ¡1ã€‘æ‹†åˆ†AUROCåˆ†æ")
    print("="*80)
    
    # æ•´ä½“ç»Ÿè®¡
    print("\nğŸ“Š æ•´ä½“AUROCç»Ÿè®¡:")
    print(f"  Overall Semantic: {df['overall_semantic_auroc'].mean():.4f} Â± {df['overall_semantic_auroc'].std():.4f}")
    print(f"  Overall Fusion:   {df['overall_fusion_auroc'].mean():.4f} Â± {df['overall_fusion_auroc'].std():.4f}")
    
    print(f"\n  Normal-only Semantic: {df['normal_semantic_auroc'].mean():.4f} Â± {df['normal_semantic_auroc'].std():.4f}")
    print(f"  Normal-only Fusion:   {df['normal_fusion_auroc'].mean():.4f} Â± {df['normal_fusion_auroc'].std():.4f}")
    
    print(f"\n  Abnormal-only Semantic: {df['abnormal_semantic_auroc'].mean():.4f} Â± {df['abnormal_semantic_auroc'].std():.4f}")
    print(f"  Abnormal-only Fusion:   {df['abnormal_fusion_auroc'].mean():.4f} Â± {df['abnormal_fusion_auroc'].std():.4f}")
    
    # æŒ‰æ€§èƒ½ç»„ç»Ÿè®¡
    print("\nğŸ“Š æŒ‰æ€§èƒ½ç»„åˆ†å±‚:")
    for group in ['Severe Degrade', 'Mild Degrade', 'Stable', 'Improved']:
        group_df = df[df['performance_group'] == group]
        if len(group_df) == 0:
            continue
        print(f"\n  {group} (n={len(group_df)}):")
        print(f"    Overall AUROC: {group_df['overall_semantic_auroc'].mean():.4f}")
        print(f"    Normal-only:   {group_df['normal_semantic_auroc'].mean():.4f}")
        print(f"    Abnormal-only: {group_df['abnormal_semantic_auroc'].mean():.4f}")
    
    # å®šæ€§ç»“è®º
    print("\nğŸ’¡ å®šæ€§ç»“è®º:")
    
    # 1. Normal vs Abnormalä¾§å“ªä¸ªæ›´å·®ï¼Ÿ
    normal_mean = df['normal_semantic_auroc'].mean()
    abnormal_mean = df['abnormal_semantic_auroc'].mean()
    
    if normal_mean < abnormal_mean - 0.05:
        print(f"  âœ… è¯æ®å……åˆ†: Normalä¾§åŒºåˆ†èƒ½åŠ›æ›´å·® ({normal_mean:.3f} < {abnormal_mean:.3f})")
        print(f"     â†’ å‡é˜³æ€§é—®é¢˜ä¸¥é‡ï¼ˆæ­£å¸¸æ ·æœ¬è¢«è¯¯åˆ¤ä¸ºå¼‚å¸¸ï¼‰")
    elif abnormal_mean < normal_mean - 0.05:
        print(f"  âœ… è¯æ®å……åˆ†: Abnormalä¾§åŒºåˆ†èƒ½åŠ›æ›´å·® ({abnormal_mean:.3f} < {normal_mean:.3f})")
        print(f"     â†’ å¬å›ä¸è¶³é—®é¢˜ä¸¥é‡ï¼ˆå¼‚å¸¸æ ·æœ¬æœªè¢«æ£€å‡ºï¼‰")
    else:
        print(f"  âš–ï¸ è¶‹åŠ¿ä¸æ˜æ˜¾: Normal ({normal_mean:.3f}) ä¸ Abnormal ({abnormal_mean:.3f}) ç›¸å½“")
    
    # 2. é€€åŒ–ç±»åˆ«çš„ç‰¹å¾
    severe_df = df[df['performance_group'] == 'Severe Degrade']
    stable_df = df[df['performance_group'] == 'Stable']
    
    if len(severe_df) > 0 and len(stable_df) > 0:
        severe_normal = severe_df['normal_semantic_auroc'].mean()
        stable_normal = stable_df['normal_semantic_auroc'].mean()
        
        if severe_normal < stable_normal - 0.05:
            print(f"  âœ… è¯æ®å……åˆ†: Severeç»„Normalä¾§æ›´å·® ({severe_normal:.3f} < {stable_normal:.3f})")
            print(f"     â†’ é€€åŒ–ä¸»è¦æ¥è‡ªæ­£å¸¸æ ·æœ¬è¢«è¯¯åˆ¤")


def analyze_margin_distribution(df):
    """åˆ†æMarginåˆ†å¸ƒ"""
    print("\n" + "="*80)
    print("ã€ä»»åŠ¡2ã€‘Marginåˆ†å¸ƒåˆ†æ")
    print("="*80)
    
    # æå–Normalå’ŒAbnormalç»„çš„ç»Ÿè®¡
    normal_df = df[df['group'] == 'normal']
    abnormal_df = df[df['group'] == 'abnormal']
    
    print("\nğŸ“Š æ•´ä½“Marginç»Ÿè®¡:")
    print(f"  Normalæ ·æœ¬:   å‡å€¼={normal_df['mean'].mean():.4f}, ä¸­ä½æ•°={normal_df['median'].mean():.4f}")
    print(f"  Abnormalæ ·æœ¬: å‡å€¼={abnormal_df['mean'].mean():.4f}, ä¸­ä½æ•°={abnormal_df['median'].mean():.4f}")
    print(f"  Separation:   {normal_df['mean'].mean() - abnormal_df['mean'].mean():.4f}")
    
    # åˆå¹¶æ€§èƒ½åˆ†ç»„
    performance_data = pd.read_csv('analysis/full_performance_comparison_k2.csv')
    normal_df = normal_df.merge(
        performance_data[['class', 'performance_group']],
        on='class',
        how='left'
    )
    abnormal_df = abnormal_df.merge(
        performance_data[['class', 'performance_group']],
        on='class',
        how='left'
    )
    
    print("\nğŸ“Š æŒ‰æ€§èƒ½ç»„åˆ†å±‚:")
    for group in ['Severe Degrade', 'Mild Degrade', 'Stable', 'Improved']:
        normal_group = normal_df[normal_df['performance_group'] == group]
        abnormal_group = abnormal_df[abnormal_df['performance_group'] == group]
        
        if len(normal_group) == 0:
            continue
        
        print(f"\n  {group} (n={len(normal_group)}):")
        print(f"    Normal Margin:   {normal_group['mean'].mean():.4f} (P10={normal_group['p10'].mean():.4f})")
        print(f"    Abnormal Margin: {abnormal_group['mean'].mean():.4f} (P90={abnormal_group['p90'].mean():.4f})")
        print(f"    Separation:      {normal_group['mean'].mean() - abnormal_group['mean'].mean():.4f}")
    
    # å®šæ€§ç»“è®º
    print("\nğŸ’¡ å®šæ€§ç»“è®º:")
    
    # 1. Marginæ˜¯å¦è¶³å¤Ÿï¼Ÿ
    normal_mean = normal_df['mean'].mean()
    abnormal_mean = abnormal_df['mean'].mean()
    separation = normal_mean - abnormal_mean
    
    if separation < 0.1:
        print(f"  âœ… è¯æ®å……åˆ†: Marginä¸¥é‡ä¸è¶³ (separation={separation:.4f})")
        print(f"     â†’ Normal-Abnormalåˆ¤åˆ«è¾¹ç•Œè¿‡çª„")
    elif separation < 0.2:
        print(f"  âš–ï¸ è¶‹åŠ¿æ˜æ˜¾: Marginåä½ (separation={separation:.4f})")
    
    # 2. å“ªä¸€ä¾§Marginæ›´å°ï¼Ÿ
    normal_p10 = normal_df['p10'].mean()
    abnormal_p90 = abnormal_df['p90'].mean()
    
    if normal_p10 < 0:
        print(f"  âœ… è¯æ®å……åˆ†: Normalæ ·æœ¬10%åˆ†ä½æ•°ä¸ºè´Ÿ ({normal_p10:.4f})")
        print(f"     â†’ æ­£å¸¸æ ·æœ¬ä¸­æœ‰å¤§é‡è¢«è¯¯åˆ¤ä¸ºå¼‚å¸¸")
    
    if abnormal_p90 < 0:
        print(f"  âœ… è¯æ®å……åˆ†: Abnormalæ ·æœ¬90%åˆ†ä½æ•°ä¸ºè´Ÿ ({abnormal_p90:.4f})")
        print(f"     â†’ å¼‚å¸¸æ ·æœ¬ä¸­å¤šæ•°æ›´æ¥è¿‘å¼‚å¸¸åŸå‹")
    
    # 3. Severe vs Stableçš„Marginå·®å¼‚
    severe_normal = normal_df[normal_df['performance_group'] == 'Severe Degrade']
    stable_normal = normal_df[normal_df['performance_group'] == 'Stable']
    
    if len(severe_normal) > 0 and len(stable_normal) > 0:
        severe_margin = severe_normal['mean'].mean()
        stable_margin = stable_normal['mean'].mean()
        
        if stable_margin > severe_margin + 0.05:
            print(f"  âœ… è¯æ®å……åˆ†: Stableç»„Normal Marginæ›´å¤§ ({stable_margin:.3f} > {severe_margin:.3f})")
            print(f"     â†’ ç¨³å®šç±»åˆ«ç¡®å®æ‹¥æœ‰æ›´å¥½çš„åˆ¤åˆ«è£•åº¦")


def analyze_semantic_contribution(df):
    """åˆ†æSemanticè´¡çŒ®"""
    print("\n" + "="*80)
    print("ã€ä»»åŠ¡3ã€‘Semanticåˆ†æ”¯è´¡çŒ®åˆ†æ")
    print("="*80)
    
    print("\nğŸ“Š æ•´ä½“ç›¸å…³æ€§ç»Ÿè®¡:")
    print(f"  Semantic-Fusion Pearson: {df['overall_pearson'].mean():.4f} Â± {df['overall_pearson'].std():.4f}")
    print(f"    Normalä¾§:   {df['normal_pearson'].mean():.4f}")
    print(f"    Abnormalä¾§: {df['abnormal_pearson'].mean():.4f}")
    
    print(f"\n  Semantic-Visual åˆ†æ”¯å·®å¼‚:")
    print(f"    Overall: {df['semantic_visual_diff_mean'].mean():.4f}")
    print(f"    Normal:  {df['semantic_visual_diff_normal'].mean():.4f}")
    print(f"    Abnormal: {df['semantic_visual_diff_abnormal'].mean():.4f}")
    
    # æŒ‰æ€§èƒ½ç»„ç»Ÿè®¡
    print("\nğŸ“Š æŒ‰æ€§èƒ½ç»„åˆ†å±‚:")
    for group in ['Severe Degrade', 'Mild Degrade', 'Stable', 'Improved']:
        group_df = df[df['performance_group'] == group]
        if len(group_df) == 0:
            continue
        print(f"\n  {group} (n={len(group_df)}):")
        print(f"    Semantic-Fusion ç›¸å…³æ€§: {group_df['overall_pearson'].mean():.4f}")
        print(f"    Semantic-Visual å·®å¼‚:   {group_df['semantic_visual_diff_mean'].mean():.4f}")
    
    # å®šæ€§ç»“è®º
    print("\nğŸ’¡ å®šæ€§ç»“è®º:")
    
    # 1. Semanticåˆ†æ”¯è´¡çŒ®å¼ºåº¦
    overall_corr = df['overall_pearson'].mean()
    
    if overall_corr > 0.9:
        print(f"  âœ… è¯æ®å……åˆ†: Semanticä¸»å¯¼Fusion (r={overall_corr:.3f})")
        print(f"     â†’ Visualåˆ†æ”¯è´¡çŒ®è¾ƒå¼±")
    elif overall_corr > 0.7:
        print(f"  âš–ï¸ è¶‹åŠ¿æ˜æ˜¾: Semanticå¯¹Fusionè´¡çŒ®è¾ƒå¤§ (r={overall_corr:.3f})")
    else:
        print(f"  âš ï¸  å¼‚å¸¸: Semanticä¸Fusionç›¸å…³æ€§åä½ (r={overall_corr:.3f})")
    
    # 2. Normal vs Abnormalä¾§å·®å¼‚
    normal_corr = df['normal_pearson'].mean()
    abnormal_corr = df['abnormal_pearson'].mean()
    
    if abs(normal_corr - abnormal_corr) > 0.1:
        if normal_corr > abnormal_corr:
            print(f"  âš–ï¸ è¶‹åŠ¿: Normalä¾§Semanticè´¡çŒ®æ›´ç¨³å®š ({normal_corr:.3f} > {abnormal_corr:.3f})")
        else:
            print(f"  âš–ï¸ è¶‹åŠ¿: Abnormalä¾§Semanticè´¡çŒ®æ›´ç¨³å®š ({abnormal_corr:.3f} > {normal_corr:.3f})")
    
    # 3. Semantic-Visualå·®å¼‚æ˜¯å¦ä¸é€€åŒ–ç›¸å…³
    severe_df = df[df['performance_group'] == 'Severe Degrade']
    stable_df = df[df['performance_group'] == 'Stable']
    
    if len(severe_df) > 0 and len(stable_df) > 0:
        severe_diff = severe_df['semantic_visual_diff_mean'].mean()
        stable_diff = stable_df['semantic_visual_diff_mean'].mean()
        
        if abs(severe_diff - stable_diff) > 0.05:
            print(f"  âš–ï¸ è¶‹åŠ¿: Severeç»„åˆ†æ”¯å·®å¼‚{'æ›´å¤§' if severe_diff > stable_diff else 'æ›´å°'} ({severe_diff:.3f} vs {stable_diff:.3f})")


def plot_extended_metrics_summary(split_auroc_df, margin_df, semantic_df):
    """å¯è§†åŒ–æ‰©å±•æŒ‡æ ‡æ±‡æ€»"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # 1. æ‹†åˆ†AUROCå¯¹æ¯”
    ax = axes[0, 0]
    metrics = ['overall_semantic_auroc', 'normal_semantic_auroc', 'abnormal_semantic_auroc']
    means = [split_auroc_df[m].mean() for m in metrics]
    ax.bar(['Overall', 'Normal-only', 'Abnormal-only'], means, alpha=0.7)
    ax.set_ylabel('AUROC')
    ax.set_title('Split AUROC Comparison')
    ax.set_ylim([0.4, 1.0])
    ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
    ax.grid(True, alpha=0.3)
    
    # 2. Marginåˆ†å¸ƒç®±çº¿å›¾
    ax = axes[0, 1]
    normal_margins = margin_df[margin_df['group'] == 'normal']['mean'].values
    abnormal_margins = margin_df[margin_df['group'] == 'abnormal']['mean'].values
    ax.boxplot([normal_margins, abnormal_margins], labels=['Normal', 'Abnormal'])
    ax.set_ylabel('Margin (max_normal - max_abnormal)')
    ax.set_title('Margin Distribution by Label')
    ax.axhline(y=0, color='red', linestyle='--', alpha=0.7)
    ax.grid(True, alpha=0.3)
    
    # 3. Semanticç›¸å…³æ€§åˆ†å¸ƒ
    ax = axes[0, 2]
    ax.hist(semantic_df['overall_pearson'].dropna(), bins=20, alpha=0.7, edgecolor='black')
    ax.axvline(x=semantic_df['overall_pearson'].mean(), color='red', linestyle='--', 
              label=f'Mean={semantic_df["overall_pearson"].mean():.3f}')
    ax.set_xlabel('Pearson Correlation')
    ax.set_ylabel('Frequency')
    ax.set_title('Semantic-Fusion Correlation Distribution')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. æŒ‰æ€§èƒ½ç»„çš„AUROC
    ax = axes[1, 0]
    for group in ['Severe Degrade', 'Mild Degrade', 'Stable']:
        group_df = split_auroc_df[split_auroc_df['performance_group'] == group]
        if len(group_df) > 0:
            ax.scatter([group]*len(group_df), group_df['overall_semantic_auroc'], 
                      alpha=0.6, s=50, label=f'{group} (n={len(group_df)})')
    ax.set_ylabel('Overall AUROC')
    ax.set_title('AUROC by Performance Group')
    ax.legend(fontsize=8)
    ax.grid(True, alpha=0.3)
    
    # 5. Margin vs Delta_Acc
    ax = axes[1, 1]
    # éœ€è¦åˆå¹¶æ•°æ®
    performance_data = pd.read_csv('analysis/full_performance_comparison_k2.csv')
    normal_margin_df = margin_df[margin_df['group'] == 'normal'].merge(
        performance_data[['class', 'delta_acc']], on='class', how='left'
    )
    ax.scatter(normal_margin_df['mean'], normal_margin_df['delta_acc'], alpha=0.6)
    ax.set_xlabel('Normal Margin')
    ax.set_ylabel('Delta Acc (%)')
    ax.set_title('Normal Margin vs Performance Change')
    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
    ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)
    ax.grid(True, alpha=0.3)
    
    # 6. Semanticè´¡çŒ® vs Delta_Acc
    ax = axes[1, 2]
    ax.scatter(semantic_df['overall_pearson'], semantic_df['delta_acc'], alpha=0.6)
    ax.set_xlabel('Semantic-Fusion Correlation')
    ax.set_ylabel('Delta Acc (%)')
    ax.set_title('Semantic Contribution vs Performance Change')
    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    output_path = 'analysis/extended_metrics/extended_metrics_summary.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\nâœ… å¯è§†åŒ–æ±‡æ€»: {output_path}")
    plt.close()


def main():
    print("="*80)
    print("æ‰©å±•è¯„ä¼°æŒ‡æ ‡æ±‡æ€»åˆ†æ")
    print("="*80)
    
    # 1. æ±‡æ€»æ•°æ®
    print("\nğŸ“¥ æ±‡æ€»æ•°æ®æ–‡ä»¶...")
    split_auroc_df = aggregate_split_auroc()
    margin_df = aggregate_margin_stats()
    semantic_df = aggregate_semantic_contrib()
    
    if split_auroc_df is None or margin_df is None or semantic_df is None:
        print("\nâŒ æ•°æ®æ–‡ä»¶ä¸å®Œæ•´ï¼Œè¯·å…ˆè¿è¡Œ run_extended_evaluation.sh")
        return
    
    print(f"\nâœ… æˆåŠŸæ±‡æ€» {len(split_auroc_df)} ä¸ªç±»åˆ«çš„æ•°æ®")
    
    # 2. åˆ†æ
    analyze_split_auroc(split_auroc_df)
    analyze_margin_distribution(margin_df)
    analyze_semantic_contribution(semantic_df)
    
    # 3. å¯è§†åŒ–
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–...")
    plot_extended_metrics_summary(split_auroc_df, margin_df, semantic_df)
    
    # 4. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "="*80)
    print("âœ… æ‰©å±•è¯„ä¼°åˆ†æå®Œæˆï¼")
    print("="*80)
    print("\nå…³é”®æ–‡ä»¶:")
    print("  - analysis/extended_metrics/split_auroc_summary.csv")
    print("  - analysis/extended_metrics/margin_stats_summary.csv")
    print("  - analysis/extended_metrics/semantic_contrib_summary.csv")
    print("  - analysis/extended_metrics/extended_metrics_summary.png")


if __name__ == '__main__':
    main()
