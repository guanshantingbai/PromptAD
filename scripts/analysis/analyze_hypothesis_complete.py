#!/usr/bin/env python3
"""
Step 3 + Step 4C: å®Œæ•´çš„å‡è®¾éªŒè¯ä¸åˆ†å±‚åˆ†æ
åŒ…å«baseline_strengthåˆ†å±‚ç›¸å…³æ€§åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.metrics import roc_curve, auc
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

def analyze_correlation(df):
    """è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ä¸delta_accçš„ç›¸å…³æ€§"""
    print("\n" + "="*80)
    print("1ï¸âƒ£  ç›¸å…³æ€§åˆ†æ")
    print("="*80 + "\n")
    
    metrics = {
        'A_hit_mean': 'å¼‚å¸¸maxå¶ç„¶å‘½ä¸­(å‡å€¼)',
        'A_hit_p95': 'å¼‚å¸¸maxå¶ç„¶å‘½ä¸­(P95)',
        'B_separation': 'åˆ¤åˆ«åˆ†ç¦»åº¦',
        'B_overlap': 'è£•åº¦é‡å ç‡',
        'C_collapse_score': 'åŸå‹å¡Œç¼©åˆ†æ•°',
        'D_max_proto_count': 'ååŸå‹è´£ä»»(æœ€å¤§è®¡æ•°)',
        'E_semantic_gap': 'è¯­ä¹‰åˆ†æ•°åŒºåˆ†åº¦'
    }
    
    results = []
    for metric, label in metrics.items():
        # è®¡ç®—ç›¸å…³æ€§
        pearson_r, pearson_p = stats.pearsonr(df[metric], df['delta_acc'])
        spearman_r, spearman_p = stats.spearmanr(df[metric], df['delta_acc'])
        
        # æ˜¾è‘—æ€§æ ‡è®°
        def sig_mark(p):
            if p < 0.001: return '***'
            elif p < 0.01: return '**'
            elif p < 0.05: return '*'
            else: return 'ns'
        
        print(f"{label}:")
        print(f"  Pearson  r={pearson_r:7.4f}, p={pearson_p:.4f} {sig_mark(pearson_p)}")
        print(f"  Spearman Ï={spearman_r:7.4f}, p={spearman_p:.4f} {sig_mark(spearman_p)}")
        print()
        
        results.append({
            'metric': metric,
            'label': label,
            'pearson_r': pearson_r,
            'pearson_p': pearson_p,
            'spearman_r': spearman_r,
            'spearman_p': spearman_p,
            'n_samples': len(df)
        })
    
    results_df = pd.DataFrame(results)
    results_df.to_csv('analysis/correlation_results.csv', index=False)
    
    return results_df

def plot_correlation_heatmap(results_df):
    """ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Pearsonç›¸å…³æ€§
    pearson_data = results_df.set_index('label')['pearson_r'].values.reshape(-1, 1)
    pearson_p = results_df.set_index('label')['pearson_p'].values.reshape(-1, 1)
    
    sns.heatmap(pearson_data, annot=True, fmt='.3f', cmap='RdBu_r', center=0,
                vmin=-0.5, vmax=0.5, cbar_kws={'label': 'Pearson r'},
                yticklabels=results_df['label'].values, xticklabels=['Î”Acc'],
                ax=axes[0])
    axes[0].set_title('Pearson Correlation with Î”Acc', fontsize=12, pad=10)
    
    # æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
    for i, p in enumerate(pearson_p.flatten()):
        if p < 0.05:
            axes[0].text(0.5, i+0.5, '*', ha='center', va='center', 
                        color='white' if abs(pearson_data[i][0]) > 0.25 else 'black',
                        fontsize=16, weight='bold')
    
    # Spearmanç›¸å…³æ€§
    spearman_data = results_df.set_index('label')['spearman_r'].values.reshape(-1, 1)
    spearman_p = results_df.set_index('label')['spearman_p'].values.reshape(-1, 1)
    
    sns.heatmap(spearman_data, annot=True, fmt='.3f', cmap='RdBu_r', center=0,
                vmin=-0.5, vmax=0.5, cbar_kws={'label': 'Spearman Ï'},
                yticklabels=results_df['label'].values, xticklabels=['Î”Acc'],
                ax=axes[1])
    axes[1].set_title('Spearman Correlation with Î”Acc', fontsize=12, pad=10)
    
    # æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
    for i, p in enumerate(spearman_p.flatten()):
        if p < 0.05:
            axes[1].text(0.5, i+0.5, '*', ha='center', va='center',
                        color='white' if abs(spearman_data[i][0]) > 0.25 else 'black',
                        fontsize=16, weight='bold')
    
    plt.tight_layout()
    plt.savefig('analysis/correlation_heatmap.png', dpi=300, bbox_inches='tight')
    print("âœ… ç›¸å…³æ€§çƒ­åŠ›å›¾å·²ä¿å­˜: analysis/correlation_heatmap.png")
    plt.close()

def plot_scatter_matrix(df):
    """ç»˜åˆ¶å…³é”®æŒ‡æ ‡æ•£ç‚¹å›¾çŸ©é˜µ"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    key_metrics = [
        ('A_hit_mean', 'å¼‚å¸¸maxå¶ç„¶å‘½ä¸­'),
        ('B_separation', 'åˆ¤åˆ«åˆ†ç¦»åº¦'),
        ('C_collapse_score', 'åŸå‹å¡Œç¼©åˆ†æ•°'),
        ('B_overlap', 'è£•åº¦é‡å ç‡')
    ]
    
    # æ€§èƒ½ç»„é¢œè‰²æ˜ å°„
    colors = {'Severe': '#d62728', 'Mild': '#ff7f0e', 'Stable': '#2ca02c', 'Improved': '#1f77b4'}
    
    for idx, (metric, label) in enumerate(key_metrics):
        ax = axes[idx // 2, idx % 2]
        
        for group in df['performance_group'].unique():
            group_data = df[df['performance_group'] == group]
            ax.scatter(group_data[metric], group_data['delta_acc'],
                      label=group, color=colors.get(group, 'gray'), alpha=0.6, s=50)
        
        # å›å½’çº¿
        z = np.polyfit(df[metric], df['delta_acc'], 1)
        p = np.poly1d(z)
        x_line = np.linspace(df[metric].min(), df[metric].max(), 100)
        ax.plot(x_line, p(x_line), 'k--', alpha=0.5, linewidth=1.5)
        
        # ç›¸å…³ç³»æ•°
        r, p_val = stats.pearsonr(df[metric], df['delta_acc'])
        ax.text(0.05, 0.95, f'r={r:.3f}\np={p_val:.3f}',
               transform=ax.transAxes, va='top', fontsize=9,
               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        ax.set_xlabel(label, fontsize=10)
        ax.set_ylabel('Î”Acc (%)', fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)
        
        if idx == 0:
            ax.legend(loc='lower right', fontsize=8)
    
    plt.tight_layout()
    plt.savefig('analysis/scatter_matrix.png', dpi=300, bbox_inches='tight')
    print("âœ… æ•£ç‚¹å›¾çŸ©é˜µå·²ä¿å­˜: analysis/scatter_matrix.png")
    plt.close()

def group_comparison(df):
    """æŒ‰æ€§èƒ½ç»„å¯¹æ¯”æŒ‡æ ‡åˆ†å¸ƒ"""
    print("\n" + "="*80)
    print("2ï¸âƒ£  åˆ†ç»„å¯¹æ¯”åˆ†æ")
    print("="*80)
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    metrics = [
        ('B_separation', 'åˆ¤åˆ«åˆ†ç¦»åº¦'),
        ('C_collapse_score', 'åŸå‹å¡Œç¼©åˆ†æ•°'),
        ('A_hit_mean', 'å¼‚å¸¸maxå¶ç„¶å‘½ä¸­'),
        ('B_overlap', 'è£•åº¦é‡å ç‡')
    ]
    
    colors = {'Severe': '#d62728', 'Mild': '#ff7f0e', 'Stable': '#2ca02c', 'Improved': '#1f77b4'}
    
    for idx, (metric, label) in enumerate(metrics):
        ax = axes[idx // 2, idx % 2]
        
        data_by_group = [df[df['performance_group'] == g][metric].values 
                        for g in ['Severe', 'Mild', 'Stable', 'Improved']]
        
        bp = ax.boxplot(data_by_group, labels=['Severe', 'Mild', 'Stable', 'Improved'],
                       patch_artist=True, widths=0.6)
        
        for patch, group in zip(bp['boxes'], ['Severe', 'Mild', 'Stable', 'Improved']):
            patch.set_facecolor(colors[group])
            patch.set_alpha(0.7)
        
        ax.set_ylabel(label, fontsize=10)
        ax.set_xlabel('Performance Group', fontsize=10)
        ax.grid(True, alpha=0.3, axis='y')
        ax.tick_params(axis='x', rotation=15)
    
    plt.tight_layout()
    plt.savefig('analysis/group_comparison.png', dpi=300, bbox_inches='tight')
    print("âœ… åˆ†ç»„å¯¹æ¯”ç®±çº¿å›¾å·²ä¿å­˜: analysis/group_comparison.png\n")
    
    # ç»Ÿè®¡æ¯ç»„å‡å€¼
    group_stats = df.groupby('performance_group')[['B_separation', 'C_collapse_score', 
                                                    'A_hit_mean', 'B_overlap']].mean()
    print("ğŸ“Š å„ç»„æŒ‡æ ‡å‡å€¼:")
    print(group_stats.to_string(float_format=lambda x: f"{x:.6f}"))
    
    # ä¿å­˜è¯¦ç»†ç»Ÿè®¡
    detailed_stats = []
    for metric in ['C_collapse_score', 'B_separation', 'B_overlap', 'A_hit_mean']:
        for group in df['performance_group'].unique():
            group_data = df[df['performance_group'] == group][metric]
            detailed_stats.append({
                'metric': metric,
                'group': group,
                'mean': group_data.mean(),
                'std': group_data.std(),
                'median': group_data.median(),
                'n': len(group_data)
            })
    
    pd.DataFrame(detailed_stats).to_csv('analysis/group_statistics.csv', index=False)
    plt.close()

def baseline_strength_analysis(df):
    """æŒ‰baselineå¼ºåº¦åˆ†å±‚çš„ç›¸å…³æ€§åˆ†æ - Step 4C"""
    print("\n" + "="*80)
    print("3ï¸âƒ£  Baselineå¼ºåº¦åˆ†å±‚åˆ†æ (Step 4C)")
    print("="*80 + "\n")
    
    metrics = {
        'A_hit_mean': 'å¼‚å¸¸maxå¶ç„¶å‘½ä¸­',
        'B_separation': 'åˆ¤åˆ«åˆ†ç¦»åº¦',
        'B_overlap': 'è£•åº¦é‡å ç‡',
        'C_collapse_score': 'åŸå‹å¡Œç¼©åˆ†æ•°'
    }
    
    stratified_results = []
    
    for strength in ['Strong', 'Medium', 'Weak']:
        subset = df[df['baseline_strength'] == strength]
        n = len(subset)
        
        if n < 3:
            print(f"âš ï¸  {strength} ç»„æ ·æœ¬é‡ä¸è¶³ (n={n})ï¼Œè·³è¿‡åˆ†æ\n")
            continue
        
        print(f"ğŸ“Š {strength} Baseline (n={n}):")
        print(f"   Baselineå‡†ç¡®ç‡èŒƒå›´: {subset['baseline_acc'].min():.2f}% - {subset['baseline_acc'].max():.2f}%")
        print(f"   å¹³å‡Î”Acc: {subset['delta_acc'].mean():.2f}%")
        print(f"   æ€§èƒ½åˆ†ç»„: {subset['performance_group'].value_counts().to_dict()}\n")
        
        for metric, label in metrics.items():
            if subset[metric].std() < 1e-6:  # æ–¹å·®è¿‡å°
                print(f"   {label}: æ–¹å·®è¿‡å°ï¼Œæ— æ³•è®¡ç®—ç›¸å…³æ€§")
                continue
            
            pearson_r, pearson_p = stats.pearsonr(subset[metric], subset['delta_acc'])
            spearman_r, spearman_p = stats.spearmanr(subset[metric], subset['delta_acc'])
            
            def sig_mark(p):
                if p < 0.05: return '*'
                else: return 'ns'
            
            print(f"   {label}:")
            print(f"      Pearson  r={pearson_r:6.3f}, p={pearson_p:.3f} {sig_mark(pearson_p)}")
            print(f"      Spearman Ï={spearman_r:6.3f}, p={spearman_p:.3f} {sig_mark(spearman_p)}")
            
            stratified_results.append({
                'baseline_strength': strength,
                'n_samples': n,
                'metric': metric,
                'label': label,
                'pearson_r': pearson_r,
                'pearson_p': pearson_p,
                'spearman_r': spearman_r,
                'spearman_p': spearman_p,
                'mean_delta_acc': subset['delta_acc'].mean(),
                'metric_mean': subset[metric].mean(),
                'metric_std': subset[metric].std()
            })
        
        print()
    
    # ä¿å­˜åˆ†å±‚ç»“æœ
    stratified_df = pd.DataFrame(stratified_results)
    stratified_df.to_csv('analysis/baseline_strength_correlations.csv', index=False)
    print("âœ… åˆ†å±‚ç›¸å…³æ€§åˆ†æå·²ä¿å­˜: analysis/baseline_strength_correlations.csv\n")
    
    # å¯è§†åŒ–åˆ†å±‚ç›¸å…³æ€§
    plot_stratified_correlations(stratified_df)
    
    return stratified_df

def plot_stratified_correlations(stratified_df):
    """å¯è§†åŒ–åˆ†å±‚ç›¸å…³æ€§ç»“æœ"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    metrics = ['B_separation', 'C_collapse_score', 'B_overlap', 'A_hit_mean']
    labels = ['åˆ¤åˆ«åˆ†ç¦»åº¦', 'åŸå‹å¡Œç¼©åˆ†æ•°', 'è£•åº¦é‡å ç‡', 'å¼‚å¸¸maxå¶ç„¶å‘½ä¸­']
    
    for idx, (metric, label) in enumerate(zip(metrics, labels)):
        ax = axes[idx // 2, idx % 2]
        
        metric_data = stratified_df[stratified_df['metric'] == metric]
        
        x = np.arange(len(metric_data))
        width = 0.35
        
        pearson_bars = ax.bar(x - width/2, metric_data['pearson_r'], width, 
                             label='Pearson r', alpha=0.8)
        spearman_bars = ax.bar(x + width/2, metric_data['spearman_r'], width,
                              label='Spearman Ï', alpha=0.8)
        
        # æ ‡è®°æ˜¾è‘—æ€§
        for i, row in enumerate(metric_data.itertuples()):
            if row.pearson_p < 0.05:
                ax.text(i - width/2, row.pearson_r + 0.02, '*', 
                       ha='center', fontsize=14, weight='bold')
            if row.spearman_p < 0.05:
                ax.text(i + width/2, row.spearman_r + 0.02, '*',
                       ha='center', fontsize=14, weight='bold')
        
        ax.set_ylabel('Correlation with Î”Acc', fontsize=10)
        ax.set_title(label, fontsize=11, pad=10)
        ax.set_xticks(x)
        ax.set_xticklabels(metric_data['baseline_strength'].values)
        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)
        ax.legend(fontsize=9)
        ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig('analysis/stratified_correlations.png', dpi=300, bbox_inches='tight')
    print("âœ… åˆ†å±‚ç›¸å…³æ€§å¯è§†åŒ–å·²ä¿å­˜: analysis/stratified_correlations.png")
    plt.close()

def threshold_analysis(df):
    """é˜ˆå€¼åˆ†æ - æ‰¾åˆ°é¢„æµ‹é€€åŒ–çš„æœ€ä½³é˜ˆå€¼"""
    print("\n" + "="*80)
    print("4ï¸âƒ£  é˜ˆå€¼åˆ†æï¼ˆé¢„æµ‹é€€åŒ–ï¼‰")
    print("="*80 + "\n")
    
    # å®šä¹‰é€€åŒ–æ ‡ç­¾ (Î”Acc < -2%)
    df['is_degraded'] = (df['delta_acc'] < -2).astype(int)
    
    metrics = {
        'C_collapse_score': 'åŸå‹å¡Œç¼©åˆ†æ•°',
        'B_separation': 'åˆ¤åˆ«åˆ†ç¦»åº¦',
        'B_overlap': 'è£•åº¦é‡å ç‡'
    }
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    threshold_results = []
    
    for idx, (metric, label) in enumerate(metrics.items()):
        # è®¡ç®—ROCæ›²çº¿
        if metric == 'B_separation':
            # åˆ†ç¦»åº¦è¶Šä½è¶Šå¯èƒ½é€€åŒ–ï¼Œéœ€è¦åè½¬
            fpr, tpr, thresholds = roc_curve(df['is_degraded'], -df[metric])
            thresholds = -thresholds
        else:
            fpr, tpr, thresholds = roc_curve(df['is_degraded'], df[metric])
        
        roc_auc = auc(fpr, tpr)
        
        # æ‰¾æœ€ä½³é˜ˆå€¼ (Youden's J statistic)
        j_scores = tpr - fpr
        best_idx = np.argmax(j_scores)
        best_threshold = thresholds[best_idx]
        best_sensitivity = tpr[best_idx]
        best_specificity = 1 - fpr[best_idx]
        
        # è®¡ç®—å‡†ç¡®ç‡
        if metric == 'B_separation':
            predictions = (df[metric] < best_threshold).astype(int)
        else:
            predictions = (df[metric] > best_threshold).astype(int)
        accuracy = (predictions == df['is_degraded']).mean()
        
        print(f"{label}:")
        print(f"  AUC: {roc_auc:.3f}")
        print(f"  æœ€ä½³é˜ˆå€¼: {best_threshold:.4f}")
        print(f"  çµæ•åº¦: {best_sensitivity*100:.2f}%")
        print(f"  ç‰¹å¼‚æ€§: {best_specificity*100:.2f}%")
        print(f"  å‡†ç¡®ç‡: {accuracy*100:.2f}%")
        print()
        
        threshold_results.append({
            'metric': metric,
            'label': label,
            'auc': roc_auc,
            'best_threshold': best_threshold,
            'sensitivity': best_sensitivity,
            'specificity': best_specificity,
            'accuracy': accuracy
        })
        
        # ç»˜åˆ¶ROCæ›²çº¿
        ax = axes[idx]
        ax.plot(fpr, tpr, linewidth=2, label=f'AUC = {roc_auc:.3f}')
        ax.plot([0, 1], [0, 1], 'k--', linewidth=1)
        ax.scatter([fpr[best_idx]], [tpr[best_idx]], s=100, c='red', 
                  marker='o', label=f'Best: {best_threshold:.3f}')
        ax.set_xlabel('False Positive Rate', fontsize=10)
        ax.set_ylabel('True Positive Rate', fontsize=10)
        ax.set_title(label, fontsize=11, pad=10)
        ax.legend(fontsize=9)
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('analysis/roc_curves.png', dpi=300, bbox_inches='tight')
    print("âœ… ROCæ›²çº¿å·²ä¿å­˜: analysis/roc_curves.png")
    
    pd.DataFrame(threshold_results).to_csv('analysis/threshold_analysis.csv', index=False)
    plt.close()

def main():
    print("="*80)
    print("Step 3 + Step 4C: ç›¸å…³æ€§ä¸åˆ†å±‚åˆ†æ - å®Œæ•´éªŒè¯")
    print("="*80)
    
    # è¯»å–æ•°æ®
    df = pd.read_csv('analysis/full_metrics_k2.csv')
    
    # è®¡ç®—è¯­ä¹‰åˆ†æ•°åŒºåˆ†åº¦
    df['E_semantic_gap'] = abs(df['E_abnormal_semantic'] - df['E_normal_semantic'])
    
    print(f"âœ… åŠ è½½æ•°æ®: {len(df)} ä¸ªç±»åˆ«\n")
    
    # Step 3: æ•´ä½“ç›¸å…³æ€§åˆ†æ
    results_df = analyze_correlation(df)
    plot_correlation_heatmap(results_df)
    plot_scatter_matrix(df)
    
    # Step 3: æ€§èƒ½ç»„å¯¹æ¯”
    group_comparison(df)
    
    # Step 4C: Baselineå¼ºåº¦åˆ†å±‚åˆ†æï¼ˆå…³é”®ï¼ï¼‰
    stratified_df = baseline_strength_analysis(df)
    
    # Step 3: é˜ˆå€¼åˆ†æ
    threshold_analysis(df)
    
    print("\n" + "="*80)
    print("âœ… Step 3 + Step 4C å®Œæˆï¼")
    print("="*80 + "\n")
    print("å…³é”®æ–‡ä»¶:")
    print("  - analysis/correlation_results.csv")
    print("  - analysis/baseline_strength_correlations.csv  â­ Step 4C")
    print("  - analysis/correlation_heatmap.png")
    print("  - analysis/scatter_matrix.png")
    print("  - analysis/stratified_correlations.png  â­ Step 4C")
    print("  - analysis/group_comparison.png")
    print("  - analysis/roc_curves.png\n")

if __name__ == '__main__':
    main()
