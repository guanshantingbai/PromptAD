#!/usr/bin/env python3
"""
å—æ§å®éªŒåˆ†æï¼šå¯¹æ¯”4ä¸ªç‰ˆæœ¬
- Baseline (n_pro=3)
- Prompt2 (n_pro=1, åŸå§‹EMA)
- Ours_v1 (EMAä¿®æ­£ + Repulsion + Margin)
- Ours_v2 (EMAä¿®æ­£ + Repulsion, æ— Margin) â† å—æ§å®éªŒ

éªŒè¯å‡è®¾ï¼š
1. ç§»é™¤Margin Lossåï¼ŒStableç±»Separationä¸å†ä¸‹é™
2. å¢å¼ºRepulsion (0.1) åï¼ŒCollapseå‡å°‘æ›´æ˜æ˜¾
3. è¯­ä¹‰AUROCæå‡æ›´ç¨³å®š
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr

plt.rcParams['font.size'] = 10
plt.rcParams['figure.figsize'] = (18, 14)

# è®­ç»ƒæ—¥å¿—AUROCï¼ˆä¼šåœ¨è®­ç»ƒå®Œæˆåæ›´æ–°ï¼‰
training_auroc = {
    'toothbrush': {'prompt2': 86.94, 'v1': 88.61, 'v2': None},
    'capsule': {'prompt2': 64.46, 'v1': 67.41, 'v2': None},
    'carpet': {'prompt2': 100.0, 'v1': 100.0, 'v2': None},
    'leather': {'prompt2': 100.0, 'v1': 99.93, 'v2': None},
    'screw': {'prompt2': 73.36, 'v1': 75.49, 'v2': None},
    'pcb2': {'prompt2': 66.71, 'v1': 66.61, 'v2': None},
}

def load_extended_metrics(class_key, version):
    """åŠ è½½Extended Metrics"""
    dataset, cls = class_key.split('-')
    
    # Split AUROC
    split_file = f'analysis/controlled_comparison/{dataset}_{cls}_{version}_split_auroc.csv'
    margin_file = f'analysis/controlled_comparison/{dataset}_{cls}_{version}_margin_stats.csv'
    
    try:
        df_split = pd.read_csv(split_file)
        df_margin = pd.read_csv(margin_file)
        
        normal_row = df_margin[df_margin['group'] == 'normal']
        abnormal_row = df_margin[df_margin['group'] == 'abnormal']
        
        return {
            'semantic_auroc': df_split['overall_semantic_auroc'].values[0] * 100,
            'fusion_auroc': df_split['overall_fusion_auroc'].values[0] * 100,
            'separation': normal_row['mean'].values[0] - abnormal_row['mean'].values[0],
            'normal_margin': normal_row['mean'].values[0],
        }
    except:
        return None


# åˆ†æç±»åˆ«
classes = ['mvtec-toothbrush', 'mvtec-capsule', 'visa-pcb2', 
           'mvtec-carpet', 'mvtec-leather', 'mvtec-screw']

print("="*100)
print("å—æ§å®éªŒåˆ†æï¼š4ç‰ˆæœ¬å¯¹æ¯”")
print("="*100)
print()

# æå–è®­ç»ƒAUROCï¼ˆv2éœ€è¦æ‰‹åŠ¨æ›´æ–°ï¼‰
print("ã€æ­¥éª¤1ã€‘æå–è®­ç»ƒæ—¥å¿—AUROCï¼ˆv2ç‰ˆæœ¬ï¼‰")
print("-"*100)
print("è¯·ä»è®­ç»ƒæ—¥å¿—ä¸­æå–v2çš„Image-AUROC:")

for cls in classes:
    cls_name = cls.split('-')[1]
    dataset = cls.split('-')[0]
    log_file = f'logs/controlled_exp/{dataset}_{cls_name}_k2.log'
    
    try:
        with open(log_file, 'r') as f:
            lines = f.readlines()
            for line in reversed(lines):
                if 'Image-AUROC:' in line:
                    auroc = float(line.split('Image-AUROC:')[1].strip())
                    training_auroc[cls_name]['v2'] = auroc
                    print(f"  {cls:<25} v2 AUROC: {auroc:.2f}")
                    break
    except:
        print(f"  {cls:<25} v2 AUROC: [æœªæ‰¾åˆ°æ—¥å¿—]")

print()

# åŠ è½½Extended Metrics
print("ã€æ­¥éª¤2ã€‘åŠ è½½Extended Metrics")
print("-"*100)

rows = []
for cls in classes:
    baseline = load_extended_metrics(cls, 'baseline')
    prompt2 = load_extended_metrics(cls, 'prompt2')
    v1 = load_extended_metrics(cls, 'ours_v1')
    v2 = load_extended_metrics(cls, 'ours_v2')
    
    if not all([baseline, prompt2, v1, v2]):
        print(f"âš ï¸  {cls}: æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡")
        continue
    
    cls_name = cls.split('-')[1]
    
    # æ€§èƒ½ç»„
    if cls in ['mvtec-toothbrush', 'mvtec-capsule', 'visa-pcb2']:
        group = 'Severe'
    elif cls in ['mvtec-carpet', 'mvtec-leather']:
        group = 'Stable'
    else:
        group = 'Improved'
    
    rows.append({
        'class': cls,
        'group': group,
        # è®­ç»ƒAUROC
        'train_p2': training_auroc[cls_name]['prompt2'],
        'train_v1': training_auroc[cls_name]['v1'],
        'train_v2': training_auroc[cls_name]['v2'],
        # è¯­ä¹‰AUROC
        'sem_p2': prompt2['semantic_auroc'],
        'sem_v1': v1['semantic_auroc'],
        'sem_v2': v2['semantic_auroc'],
        # Separation
        'sep_p2': prompt2['separation'],
        'sep_v1': v1['separation'],
        'sep_v2': v2['separation'],
        # Normal Margin
        'nm_p2': prompt2['normal_margin'],
        'nm_v1': v1['normal_margin'],
        'nm_v2': v2['normal_margin'],
    })

df = pd.DataFrame(rows)

if len(df) == 0:
    print("âŒ æ— æœ‰æ•ˆæ•°æ®ï¼Œè¯·å…ˆè¿è¡Œè¯„ä¼°")
    exit(1)

print(f"âœ… åŠ è½½äº† {len(df)} ä¸ªç±»åˆ«çš„æ•°æ®")
print()

# è®¡ç®—å˜åŒ–é‡
df['train_delta_v1'] = df['train_v1'] - df['train_p2']
df['train_delta_v2'] = df['train_v2'] - df['train_p2']
df['sem_delta_v1'] = df['sem_v1'] - df['sem_p2']
df['sem_delta_v2'] = df['sem_v2'] - df['sem_p2']
df['sep_delta_v1'] = df['sep_v1'] - df['sep_p2']
df['sep_delta_v2'] = df['sep_v2'] - df['sep_p2']

# æ‰“å°è¯¦ç»†å¯¹æ¯”
print("ã€æ­¥éª¤3ã€‘è¯¦ç»†å¯¹æ¯”è¡¨")
print("="*100)
print(f"{'ç±»åˆ«':<20} {'ç»„':<10} {'è®­ç»ƒÎ”v1':<12} {'è®­ç»ƒÎ”v2':<12} {'SepÎ”v1':<12} {'SepÎ”v2':<12}")
print("-"*100)

for idx, row in df.iterrows():
    print(f"{row['class']:<20} {row['group']:<10} "
          f"{row['train_delta_v1']:>+11.2f} {row['train_delta_v2']:>+11.2f} "
          f"{row['sep_delta_v1']:>+11.4f} {row['sep_delta_v2']:>+11.4f}")

print("="*100)
print()

# åˆ†ç»„ç»Ÿè®¡
print("ã€æ­¥éª¤4ã€‘åˆ†ç»„å¯¹æ¯”")
print("="*100)

for group in ['Severe', 'Stable', 'Improved']:
    group_df = df[df['group'] == group]
    if len(group_df) == 0:
        continue
    
    print(f"\nã€{group}ã€‘(n={len(group_df)})")
    print(f"  è®­ç»ƒAUROCå˜åŒ–:")
    print(f"    v1 (å…¨æ”¹åŠ¨):   {group_df['train_delta_v1'].mean():>+8.2f}%")
    print(f"    v2 (EMA+Rep):  {group_df['train_delta_v2'].mean():>+8.2f}%")
    print(f"  è¯­ä¹‰AUROCå˜åŒ–:")
    print(f"    v1:            {group_df['sem_delta_v1'].mean():>+8.2f}%")
    print(f"    v2:            {group_df['sem_delta_v2'].mean():>+8.2f}%")
    print(f"  Separationå˜åŒ–:")
    print(f"    v1 (æœ‰Margin): {group_df['sep_delta_v1'].mean():>+8.4f}")
    print(f"    v2 (æ— Margin): {group_df['sep_delta_v2'].mean():>+8.4f}")

print("\n" + "="*100)
print()

# å‡è®¾éªŒè¯
print("ã€æ­¥éª¤5ã€‘å‡è®¾éªŒè¯")
print("="*100)
print()

# å‡è®¾1ï¼šç§»é™¤Marginåï¼ŒStableç»„Separationä¸å†ä¸‹é™
stable_sep_v1 = df[df['group'] == 'Stable']['sep_delta_v1'].mean()
stable_sep_v2 = df[df['group'] == 'Stable']['sep_delta_v2'].mean()

print(f"å‡è®¾1ï¼šç§»é™¤Margin Lossåï¼ŒStableç±»Separationä¸å†ä¸¥é‡ä¸‹é™")
print(f"  Stableç»„Separationå˜åŒ–:")
print(f"    v1 (æœ‰Margin): {stable_sep_v1:+.4f}")
print(f"    v2 (æ— Margin): {stable_sep_v2:+.4f}")

if stable_sep_v2 > stable_sep_v1 and stable_sep_v2 > -0.02:
    print(f"  âœ… å‡è®¾æˆç«‹ï¼šv2çš„Separationä¸‹é™æ˜¾è‘—å‡è½»")
elif stable_sep_v2 > stable_sep_v1:
    print(f"  âš–ï¸  éƒ¨åˆ†æˆç«‹ï¼šv2ç•¥å¥½äºv1ï¼Œä½†ä»æœ‰ä¸‹é™")
else:
    print(f"  âŒ å‡è®¾ä¸æˆç«‹ï¼šv2çš„Separationä»ç„¶ä¸‹é™")

print()

# å‡è®¾2ï¼šå¢å¼ºRepulsionåï¼Œæ•´ä½“æ€§èƒ½æ›´ç¨³å®š
overall_train_v1 = df['train_delta_v1'].mean()
overall_train_v2 = df['train_delta_v2'].mean()

print(f"å‡è®¾2ï¼šå¢å¼ºRepulsionåï¼Œæ•´ä½“è®­ç»ƒAUROCæå‡æ›´æ˜æ˜¾")
print(f"  æ•´ä½“è®­ç»ƒAUROCå˜åŒ–:")
print(f"    v1 (Rep=0.05): {overall_train_v1:+.2f}%")
print(f"    v2 (Rep=0.10): {overall_train_v2:+.2f}%")

if overall_train_v2 > overall_train_v1 + 0.5:
    print(f"  âœ… å‡è®¾æˆç«‹ï¼šv2æ˜¾è‘—ä¼˜äºv1")
elif overall_train_v2 > overall_train_v1:
    print(f"  âš–ï¸  éƒ¨åˆ†æˆç«‹ï¼šv2ç•¥ä¼˜äºv1")
else:
    print(f"  âŒ å‡è®¾ä¸æˆç«‹ï¼šv2æœªä¼˜äºv1")

print()

# å‡è®¾3ï¼šv2ç›¸å¯¹v1ï¼Œæ”¹å–„/é€€åŒ–ç±»åˆ«æ•°é‡
improve_v1 = (df['train_delta_v1'] > 0).sum()
improve_v2 = (df['train_delta_v2'] > 0).sum()

print(f"å‡è®¾3ï¼šv2çš„æ”¹å–„ç±»åˆ«æ¯”ä¾‹ä¸ä½äºv1")
print(f"  æ”¹å–„ç±»åˆ«æ•°:")
print(f"    v1: {improve_v1}/{len(df)}")
print(f"    v2: {improve_v2}/{len(df)}")

if improve_v2 >= improve_v1:
    print(f"  âœ… å‡è®¾æˆç«‹")
else:
    print(f"  âŒ å‡è®¾ä¸æˆç«‹")

print()
print("="*100)
print()

# å¯è§†åŒ–
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# 1. è®­ç»ƒAUROCå˜åŒ–å¯¹æ¯”
ax = axes[0, 0]
x = np.arange(len(df))
width = 0.35
ax.bar(x - width/2, df['train_delta_v1'], width, label='v1 (å…¨æ”¹åŠ¨)', alpha=0.8)
ax.bar(x + width/2, df['train_delta_v2'], width, label='v2 (EMA+Rep)', alpha=0.8)
ax.set_xticks(x)
ax.set_xticklabels([c.split('-')[1] for c in df['class']], rotation=45, ha='right')
ax.set_ylabel('Train AUROC Change (%)')
ax.set_title('(A) è®­ç»ƒAUROCå˜åŒ–å¯¹æ¯”')
ax.axhline(y=0, color='black', linestyle='--', linewidth=0.8)
ax.legend()
ax.grid(True, alpha=0.3, axis='y')

# 2. è¯­ä¹‰AUROCå˜åŒ–å¯¹æ¯”
ax = axes[0, 1]
ax.bar(x - width/2, df['sem_delta_v1'], width, label='v1', alpha=0.8)
ax.bar(x + width/2, df['sem_delta_v2'], width, label='v2', alpha=0.8)
ax.set_xticks(x)
ax.set_xticklabels([c.split('-')[1] for c in df['class']], rotation=45, ha='right')
ax.set_ylabel('Semantic AUROC Change (%)')
ax.set_title('(B) è¯­ä¹‰AUROCå˜åŒ–å¯¹æ¯”')
ax.axhline(y=0, color='black', linestyle='--', linewidth=0.8)
ax.legend()
ax.grid(True, alpha=0.3, axis='y')

# 3. Separationå˜åŒ–å¯¹æ¯”ï¼ˆå…³é”®ï¼‰
ax = axes[0, 2]
ax.bar(x - width/2, df['sep_delta_v1'], width, label='v1 (æœ‰Margin)', alpha=0.8, color='red')
ax.bar(x + width/2, df['sep_delta_v2'], width, label='v2 (æ— Margin)', alpha=0.8, color='green')
ax.set_xticks(x)
ax.set_xticklabels([c.split('-')[1] for c in df['class']], rotation=45, ha='right')
ax.set_ylabel('Separation Change')
ax.set_title('(C) Separationå˜åŒ–å¯¹æ¯” [å…³é”®éªŒè¯]')
ax.axhline(y=0, color='black', linestyle='--', linewidth=0.8)
ax.legend()
ax.grid(True, alpha=0.3, axis='y')

# 4. æŒ‰ç»„æ±‡æ€» - è®­ç»ƒAUROC
ax = axes[1, 0]
group_train_v1 = df.groupby('group')['train_delta_v1'].mean()
group_train_v2 = df.groupby('group')['train_delta_v2'].mean()
x_group = np.arange(len(group_train_v1))
ax.bar(x_group - width/2, group_train_v1, width, label='v1', alpha=0.8)
ax.bar(x_group + width/2, group_train_v2, width, label='v2', alpha=0.8)
ax.set_xticks(x_group)
ax.set_xticklabels(group_train_v1.index)
ax.set_ylabel('Avg Train AUROC Change (%)')
ax.set_title('(D) æŒ‰ç»„æ±‡æ€» - è®­ç»ƒAUROC')
ax.axhline(y=0, color='black', linestyle='--', linewidth=0.8)
ax.legend()
ax.grid(True, alpha=0.3, axis='y')

# 5. æŒ‰ç»„æ±‡æ€» - Separation
ax = axes[1, 1]
group_sep_v1 = df.groupby('group')['sep_delta_v1'].mean()
group_sep_v2 = df.groupby('group')['sep_delta_v2'].mean()
ax.bar(x_group - width/2, group_sep_v1, width, label='v1 (æœ‰Margin)', alpha=0.8, color='red')
ax.bar(x_group + width/2, group_sep_v2, width, label='v2 (æ— Margin)', alpha=0.8, color='green')
ax.set_xticks(x_group)
ax.set_xticklabels(group_sep_v1.index)
ax.set_ylabel('Avg Separation Change')
ax.set_title('(E) æŒ‰ç»„æ±‡æ€» - Separation [å…³é”®]')
ax.axhline(y=0, color='black', linestyle='--', linewidth=0.8)
ax.legend()
ax.grid(True, alpha=0.3, axis='y')

# 6. Stableç»„ä¸“é¡¹å¯¹æ¯”
ax = axes[1, 2]
stable_data = df[df['group'] == 'Stable']
metrics = ['è®­ç»ƒAUROC', 'è¯­ä¹‰AUROC', 'SeparationÃ—10']
v1_vals = [stable_data['train_delta_v1'].mean(), 
           stable_data['sem_delta_v1'].mean(),
           stable_data['sep_delta_v1'].mean() * 10]
v2_vals = [stable_data['train_delta_v2'].mean(),
           stable_data['sem_delta_v2'].mean(),
           stable_data['sep_delta_v2'].mean() * 10]
x_metric = np.arange(len(metrics))
ax.bar(x_metric - width/2, v1_vals, width, label='v1', alpha=0.8)
ax.bar(x_metric + width/2, v2_vals, width, label='v2', alpha=0.8)
ax.set_xticks(x_metric)
ax.set_xticklabels(metrics)
ax.set_ylabel('Change')
ax.set_title('(F) Stableç»„ä¸“é¡¹å¯¹æ¯”')
ax.axhline(y=0, color='black', linestyle='--', linewidth=0.8)
ax.legend()
ax.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('analysis/controlled_comparison/controlled_experiment_analysis.png', dpi=300, bbox_inches='tight')
print(f"âœ… å¯è§†åŒ–å·²ä¿å­˜: analysis/controlled_comparison/controlled_experiment_analysis.png")
print()

# ä¿å­˜æ•°æ®
df.to_csv('analysis/controlled_comparison/controlled_experiment_data.csv', index=False, float_format='%.4f')
print(f"âœ… æ•°æ®å·²ä¿å­˜: analysis/controlled_comparison/controlled_experiment_data.csv")
print()

# æœ€ç»ˆç»“è®º
print("="*100)
print("ğŸ’¡ å—æ§å®éªŒç»“è®º")
print("="*100)
print()

if stable_sep_v2 > -0.02 and overall_train_v2 > overall_train_v1:
    print("âœ… å—æ§å®éªŒæˆåŠŸï¼")
    print("   - ç§»é™¤Margin Lossåï¼ŒStableç±»Separationä¸‹é™æ˜¾è‘—å‡è½»")
    print("   - å¢å¼ºRepulsionåï¼Œæ•´ä½“æ€§èƒ½æå‡æ›´æ˜æ˜¾")
    print("   â†’ å»ºè®®ï¼šé‡‡ç”¨v2é…ç½®ï¼ˆEMA+Repï¼‰ï¼Œæ‰©å±•åˆ°27ç±»éªŒè¯")
elif stable_sep_v2 > stable_sep_v1:
    print("âš–ï¸  éƒ¨åˆ†æˆåŠŸ")
    print("   - Separationä¸‹é™æœ‰æ‰€æ”¹å–„ï¼Œä½†å¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
    print("   â†’ å»ºè®®ï¼šè€ƒè™‘å•ç‹¬æµ‹è¯•EMA-onlyé…ç½®")
else:
    print("âŒ å—æ§å®éªŒæœªè¾¾é¢„æœŸ")
    print("   - Separationä»ç„¶ä¸‹é™æˆ–æ€§èƒ½æœªæ”¹å–„")
    print("   â†’ å»ºè®®ï¼šé‡æ–°å®¡è§†EMAå’ŒRepulsionçš„å®ç°")

print()
print("="*100)
