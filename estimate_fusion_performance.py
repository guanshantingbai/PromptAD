#!/usr/bin/env python3
"""
ä¼°è®¡ä¿®å¤åçš„èåˆæ€§èƒ½

æ€è·¯ï¼š
1. ä¿®å¤åçš„è¯­ä¹‰åˆ†æ”¯æ€§èƒ½å·²çŸ¥ï¼ˆtest_all_key_classes.pyç»“æœï¼‰
2. Memory Bankçš„æ€§èƒ½å¯ä»¥ä»baselineä¸­æ¨ç®—ï¼ˆbaselineä¹Ÿæœ‰memory bankï¼‰
3. ç”¨harmonic meanä¼°ç®—èåˆåçš„æ€§èƒ½
4. å¯¹æ¯”baselineçš„èåˆæ€§èƒ½
"""

import numpy as np
import pandas as pd

print("="*80)
print("ä¿®å¤åèåˆæ€§èƒ½ä¼°è®¡")
print("="*80)

# ==================== å·²çŸ¥æ•°æ® ====================
# 1. ä¿®å¤åçš„è¯­ä¹‰åˆ†æ”¯æ€§èƒ½ï¼ˆä»test_all_key_classes.pyï¼‰
fixed_semantic = {
    "screw": 77.35,
    "toothbrush": 89.17,
    "hazelnut": 90.86,
    "capsule": 82.21,
    "pill": 84.56,
    "metal_nut": 89.74,
}

# 2. Baselineçš„èåˆæ€§èƒ½
baseline_fusion = {
    "screw": 58.66,
    "toothbrush": 98.89,
    "hazelnut": 99.93,
    "capsule": 79.94,
    "pill": 95.61,
    "metal_nut": 100.00,
}

# 3. Baselineçš„è¯­ä¹‰æ€§èƒ½
baseline_semantic = {
    "screw": 66.42,
    "toothbrush": 69.58,
    "hazelnut": 80.11,
    "capsule": 73.69,
    "pill": 85.50,
    "metal_nut": 85.56,
}

print("\nç¬¬ä¸€æ­¥ï¼šæ¨ç®—Memory Bankçš„æ€§èƒ½")
print("-"*80)
print("Baselineä½¿ç”¨èåˆç­–ç•¥ï¼šharmonic_mean(semantic, memory_bank)")
print("å·²çŸ¥baselineçš„semanticå’Œfusionï¼Œåæ¨memory_bankæ€§èƒ½\n")

# Harmonic mean: 1/fusion = 1/semantic + 1/memory_bank
# å› æ­¤: 1/memory_bank = 1/fusion - 1/semantic
# memory_bank = 1 / (1/fusion - 1/semantic)

memory_bank_estimated = {}
print(f"{'ç±»åˆ«':<12} {'Baselineè¯­ä¹‰':<12} {'Baselineèåˆ':<12} {'æ¨ç®—Memory':<12}")
print("-"*80)

for cls in fixed_semantic.keys():
    b_sem = baseline_semantic[cls]
    b_fus = baseline_fusion[cls]
    
    # åæ¨memory bankæ€§èƒ½
    # harmonic: fusion = 1 / (1/sem + 1/mem)
    # 1/fusion = 1/sem + 1/mem
    # 1/mem = 1/fusion - 1/sem
    
    if b_fus > 0 and b_sem > 0:
        inv_mem = 1.0/b_fus - 1.0/b_sem
        if inv_mem > 0:
            mem_score = 1.0 / inv_mem
        else:
            # Memory bankå¾ˆå¼ºï¼Œå¯¼è‡´èåˆæ¯”è¯­ä¹‰è¿˜å¥½
            mem_score = b_fus * 1.5  # ç²—ç•¥ä¼°è®¡
    else:
        mem_score = 50.0  # é»˜è®¤å€¼
    
    memory_bank_estimated[cls] = mem_score
    print(f"{cls:<12} {b_sem:<12.2f} {b_fus:<12.2f} {mem_score:<12.2f}")

print("\nâš ï¸  æ³¨æ„ï¼šMemory Bankæ€§èƒ½æ˜¯åŸºäºbaselineæ¨ç®—çš„ï¼Œå®é™…å¯èƒ½æœ‰å·®å¼‚")

# ==================== ä¼°è®¡ä¿®å¤åçš„èåˆæ€§èƒ½ ====================
print("\n\nç¬¬äºŒæ­¥ï¼šä¼°è®¡ä¿®å¤åçš„èåˆæ€§èƒ½")
print("-"*80)
print("å‡è®¾ï¼šMemory Bankæ€§èƒ½ä¸baselineç±»ä¼¼ï¼ˆé‡æ–°æ„å»ºçš„memory bankï¼‰")
print("èåˆç­–ç•¥ï¼šharmonic_mean(fixed_semantic, memory_bank_estimated)\n")

estimated_fusion = {}
print(f"{'ç±»åˆ«':<12} {'ä¿®å¤åè¯­ä¹‰':<12} {'ä¼°ç®—Memory':<12} {'ä¼°ç®—èåˆ':<12} {'Baselineèåˆ':<12} {'vs Baseline':<12}")
print("-"*80)

for cls in fixed_semantic.keys():
    f_sem = fixed_semantic[cls]
    mem = memory_bank_estimated[cls]
    
    # Harmonic mean
    fusion_est = 1.0 / (1.0/f_sem + 1.0/mem)
    estimated_fusion[cls] = fusion_est
    
    b_fus = baseline_fusion[cls]
    diff = fusion_est - b_fus
    
    print(f"{cls:<12} {f_sem:<12.2f} {mem:<12.2f} {fusion_est:<12.2f} {b_fus:<12.2f} {diff:+<12.2f}")

# è®¡ç®—å¹³å‡
avg_fixed_sem = np.mean(list(fixed_semantic.values()))
avg_est_fusion = np.mean(list(estimated_fusion.values()))
avg_baseline_fusion = np.mean(list(baseline_fusion.values()))

print("-"*80)
print(f"{'å¹³å‡':<12} {avg_fixed_sem:<12.2f} {'':<12} {avg_est_fusion:<12.2f} {avg_baseline_fusion:<12.2f} {avg_est_fusion - avg_baseline_fusion:+<12.2f}")

# ==================== åœºæ™¯åˆ†æ ====================
print("\n\nç¬¬ä¸‰æ­¥ï¼šå¤šåœºæ™¯ä¼°è®¡ï¼ˆè€ƒè™‘Memory Bankå˜åŒ–ï¼‰")
print("="*80)

scenarios = {
    "ä¹è§‚åœºæ™¯": 1.1,   # Memory Bankä¹Ÿæœ‰æ‰€æå‡
    "åŸºå‡†åœºæ™¯": 1.0,   # Memory Bankä¿æŒä¸å˜
    "æ‚²è§‚åœºæ™¯": 0.9,   # Memory Bankç•¥æœ‰ä¸‹é™
}

print(f"\n{'åœºæ™¯':<12} {'ä¼°ç®—å¹³å‡èåˆ':<15} {'vs Baseline':<12} {'vs ä¿®å¤åè¯­ä¹‰':<15} {'ç»“è®º'}")
print("-"*80)

for scenario_name, factor in scenarios.items():
    # è°ƒæ•´memory bankæ€§èƒ½
    adjusted_memory = {k: v * factor for k, v in memory_bank_estimated.items()}
    
    # é‡æ–°è®¡ç®—èåˆ
    adjusted_fusion = {}
    for cls in fixed_semantic.keys():
        f_sem = fixed_semantic[cls]
        mem = adjusted_memory[cls]
        fusion = 1.0 / (1.0/f_sem + 1.0/mem)
        adjusted_fusion[cls] = fusion
    
    avg_fusion = np.mean(list(adjusted_fusion.values()))
    vs_baseline = avg_fusion - avg_baseline_fusion
    vs_semantic = avg_fusion - avg_fixed_sem
    
    if vs_baseline > 2:
        conclusion = "âœ… æ˜¾è‘—æ”¹è¿›"
    elif vs_baseline > 0:
        conclusion = "âœ… æœ‰æ‰€æ”¹è¿›"
    elif vs_baseline > -2:
        conclusion = "âš ï¸  åŸºæœ¬æŒå¹³"
    else:
        conclusion = "âŒ éœ€ä¼˜åŒ–"
    
    print(f"{scenario_name:<12} {avg_fusion:<15.2f} {vs_baseline:+<12.2f} {vs_semantic:+<15.2f} {conclusion}")

# ==================== æ€»ç»“å’Œå»ºè®® ====================
print("\n\n" + "="*80)
print("ä¼°è®¡æ€»ç»“")
print("="*80)

print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”ï¼š")
print(f"  ä¿®å¤åè¯­ä¹‰å¹³å‡: {avg_fixed_sem:.2f}%")
print(f"  ä¼°ç®—èåˆå¹³å‡:   {avg_est_fusion:.2f}%")
print(f"  Baselineèåˆ:   {avg_baseline_fusion:.2f}%")

print(f"\nğŸ“ˆ æ”¹è¿›å¹…åº¦ï¼š")
print(f"  è¯­ä¹‰ vs Baseline: {avg_fixed_sem - np.mean(list(baseline_semantic.values())):+.2f}% âœ…")
print(f"  èåˆ vs Baseline: {avg_est_fusion - avg_baseline_fusion:+.2f}%")
print(f"  èåˆ vs ä¿®å¤åè¯­ä¹‰: {avg_est_fusion - avg_fixed_sem:+.2f}%")

print("\nğŸ” å…³é”®å‘ç°ï¼š")

# åˆ†æå“ªäº›ç±»åˆ«èåˆæœ‰å¸®åŠ©ï¼Œå“ªäº›æœ‰å®³
helps = []
hurts = []
for cls in fixed_semantic.keys():
    diff = estimated_fusion[cls] - fixed_semantic[cls]
    if diff > 1:
        helps.append(f"{cls} ({diff:+.2f}%)")
    elif diff < -1:
        hurts.append(f"{cls} ({diff:+.2f}%)")

print(f"  èåˆæœ‰å¸®åŠ©çš„ç±»åˆ«: {len(helps)}/6")
if helps:
    for h in helps:
        print(f"    - {h}")

print(f"\n  èåˆæœ‰å®³çš„ç±»åˆ«: {len(hurts)}/6")
if hurts:
    for h in hurts:
        print(f"    - {h}")

print("\nğŸ’¡ ä¼°è®¡ç»“è®ºï¼š")
if avg_est_fusion > avg_baseline_fusion + 2:
    print("  âœ… èåˆåé¢„è®¡æ˜¾è‘—è¶…è¶Šbaseline")
    print(f"     ä¼°è®¡æ”¹è¿›å¹…åº¦ï¼š{avg_est_fusion - avg_baseline_fusion:+.2f}%")
    print("     å»ºè®®ï¼šç›´æ¥æµ‹è¯•èåˆæ€§èƒ½")
elif avg_est_fusion > avg_baseline_fusion:
    print("  âœ… èåˆåé¢„è®¡ç•¥å¾®è¶…è¶Šbaseline")
    print(f"     ä¼°è®¡æ”¹è¿›å¹…åº¦ï¼š{avg_est_fusion - avg_baseline_fusion:+.2f}%")
    print("     å»ºè®®ï¼šæµ‹è¯•èåˆæ€§èƒ½ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–èåˆç­–ç•¥")
elif avg_est_fusion > avg_baseline_fusion - 2:
    print("  âš ï¸  èåˆåé¢„è®¡ä¸baselineæ¥è¿‘")
    print(f"     ä¼°è®¡å·®å¼‚ï¼š{avg_est_fusion - avg_baseline_fusion:+.2f}%")
    print("     å»ºè®®ï¼šå…ˆæµ‹è¯•éªŒè¯ï¼Œè€ƒè™‘ä¼˜åŒ–èåˆç­–ç•¥")
else:
    print("  âŒ èåˆåé¢„è®¡ä¸å¦‚baseline")
    print(f"     ä¼°è®¡ä¸‹é™ï¼š{avg_est_fusion - avg_baseline_fusion:+.2f}%")
    print("     å»ºè®®ï¼šä¼˜å…ˆä¼˜åŒ–èåˆç­–ç•¥ï¼Œè€Œéç›´æ¥æµ‹è¯•")

print("\nğŸ“ åç»­æ­¥éª¤å»ºè®®ï¼š")
print("  1. è¿è¡Œèåˆæµ‹è¯•ï¼šæµ‹è¯•6ä¸ªå…³é”®ç±»åˆ«çš„èåˆæ€§èƒ½")
print("  2. å¯¹æ¯”å®é™…vsä¼°è®¡ï¼šéªŒè¯ä¼°è®¡æ¨¡å‹çš„å‡†ç¡®æ€§")
print("  3. åˆ†æå·®å¼‚åŸå› ï¼šå¦‚æœå®é™…ä¸ä¼°è®¡å·®å¼‚å¤§ï¼Œæ‰¾å‡ºåŸå› ")
print("  4. ä¼˜åŒ–èåˆç­–ç•¥ï¼šå¦‚æœèåˆä¸ç†æƒ³ï¼Œå°è¯•å…¶ä»–èåˆæ–¹æ³•")
print("     - åŠ æƒå¹³å‡ï¼ˆå¯è°ƒæƒé‡ï¼‰")
print("     - è‡ªé€‚åº”èåˆï¼ˆåŸºäºç½®ä¿¡åº¦ï¼‰")
print("     - ç±»åˆ«ç‰¹å®šèåˆç­–ç•¥")

print("\n" + "="*80)
