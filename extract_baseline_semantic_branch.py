"""
æå–baselineæ¨¡å‹çš„semanticåˆ†æ”¯AUROC
ä»baseline checkpointåŠ è½½æƒé‡ï¼Œåªä½¿ç”¨semanticåˆ†æ”¯è¿›è¡Œè¯„ä¼°
"""
import argparse
import torch
import numpy as np
from pathlib import Path
import pandas as pd
from tqdm import tqdm

from datasets import get_dataloader_from_args, dataset_classes
from utils.training_utils import setup_seed
from utils.metrics import metric_cal_img, metric_cal_pix
from PromptAD import PromptAD

DATASETS = {
    'mvtec': ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 
              'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 
              'transistor', 'wood', 'zipper'],
    'visa': ['candle', 'capsules', 'cashew', 'chewinggum', 'fryum', 
             'macaroni1', 'macaroni2', 'pcb1', 'pcb2', 'pcb3', 'pcb4', 'pipe_fryum']
}

def evaluate_semantic_branch(model, dataloader, task, device):
    """åªä½¿ç”¨semanticåˆ†æ”¯è¿›è¡Œè¯„ä¼°"""
    model.eval()
    
    if task == 'cls':
        scores = []
        gt_labels = []
        
        with torch.no_grad():
            for (data, mask, label, name, img_type) in dataloader:
                data = data.to(device)
                
                # åªè·å–semanticåˆ†æ”¯çš„åˆ†æ•°
                visual_features = model.encode_image(data)
                if isinstance(visual_features, tuple):
                    visual_features = visual_features[0]
                
                textual_score = model.calculate_textual_anomaly_score(visual_features, 'cls')
                
                scores.extend(textual_score.cpu().numpy())
                gt_labels.extend(label.numpy())
        
        # è®¡ç®—AUROC
        result_dict = metric_cal_img(np.array(scores), gt_labels, None)
        return result_dict['i_roc']
    
    else:  # seg
        score_maps = []
        gt_masks = []
        
        with torch.no_grad():
            for (data, mask, label, name, img_type) in dataloader:
                data = data.to(device)
                
                # åªè·å–semanticåˆ†æ”¯çš„å¼‚å¸¸å›¾
                visual_features = model.encode_image(data)
                textual_anomaly_map = model.calculate_textual_anomaly_score(visual_features, 'seg')
                
                score_maps.extend(textual_anomaly_map.cpu().numpy())
                
                for m in mask:
                    m = m.numpy()
                    m[m > 0] = 1
                    gt_masks.append(m)
        
        # è®¡ç®—pixel-level AUROC
        result_dict = metric_cal_pix(np.array(score_maps), gt_masks)
        return result_dict['p_roc']


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--gpu-id', type=int, default=0)
    parser.add_argument('--seed', type=int, default=111)
    parser.add_argument('--batch-size', type=int, default=32)
    parser.add_argument('--backbone', type=str, default='ViT-B-16-plus-240')
    parser.add_argument('--pretrained_dataset', type=str, default='laion400m_e32')
    parser.add_argument('--img-resize', type=int, default=240)
    parser.add_argument('--img-cropsize', type=int, default=240)
    parser.add_argument('--resolution', type=int, default=400)
    parser.add_argument('--n_ctx', type=int, default=4)
    parser.add_argument('--n_ctx_ab', type=int, default=1)
    parser.add_argument('--n_pro', type=int, default=1)
    parser.add_argument('--n_pro_ab', type=int, default=4)
    
    args = parser.parse_args()
    
    setup_seed(args.seed)
    device = f"cuda:{args.gpu_id}" if torch.cuda.is_available() else "cpu"
    
    baseline_dir = Path('result/baseline')
    results = []
    
    total_tasks = len(DATASETS['mvtec']) * 3 * 2 + len(DATASETS['visa']) * 3 * 2
    pbar = tqdm(total=total_tasks, desc="æå–semanticåˆ†æ”¯AUROC")
    
    for dataset_name, classes in DATASETS.items():
        for k_shot in [1, 2, 4]:
            checkpoint_dir = baseline_dir / dataset_name / f'k_{k_shot}' / 'checkpoint'
            
            for class_name in classes:
                for task in ['cls', 'seg']:
                    # æ„å»ºcheckpointè·¯å¾„
                    task_upper = task.upper()
                    ckpt_file = checkpoint_dir / f'{task_upper}-Seed_111-{class_name}-check_point.pt'
                    
                    if not ckpt_file.exists():
                        print(f"âš ï¸ ç¼ºå¤±: {ckpt_file}")
                        pbar.update(1)
                        continue
                    
                    try:
                        # åˆ›å»ºæ¨¡å‹
                        model = PromptAD(
                            device=device,
                            dataset=dataset_name,
                            class_name=class_name,
                            k_shot=k_shot,
                            backbone=args.backbone,
                            pretrained_dataset=args.pretrained_dataset,
                            out_size_h=args.resolution,
                            out_size_w=args.resolution,
                            n_ctx=args.n_ctx,
                            n_ctx_ab=args.n_ctx_ab,
                            n_pro=args.n_pro,
                            n_pro_ab=args.n_pro_ab,
                        )
                        model = model.to(device)
                        
                        # åŠ è½½æƒé‡
                        state_dict = torch.load(ckpt_file, map_location=device)
                        model.load_state_dict(state_dict, strict=False)
                        model.eval()
                        
                        # è·å–æ•°æ®åŠ è½½å™¨
                        dataloader, _ = get_dataloader_from_args(
                            phase='test',
                            dataset=dataset_name,
                            class_name=class_name,
                            k_shot=k_shot,
                            batch_size=args.batch_size,
                            img_resize=args.img_resize,
                            img_cropsize=args.img_cropsize,
                            perturbed=False,
                            transform=model.transform
                        )
                        
                        # è¯„ä¼°semanticåˆ†æ”¯
                        semantic_auroc = evaluate_semantic_branch(model, dataloader, task, device)
                        
                        results.append({
                            'dataset': dataset_name,
                            'class': class_name,
                            'k_shot': k_shot,
                            'task': task,
                            'semantic_auroc': round(semantic_auroc, 2)
                        })
                        
                        pbar.set_postfix({
                            'current': f"{dataset_name}/{class_name}/k{k_shot}/{task}",
                            'auroc': f"{semantic_auroc:.2f}"
                        })
                        
                        # é‡Šæ”¾æ˜¾å­˜
                        del model
                        torch.cuda.empty_cache()
                        
                    except Exception as e:
                        print(f"\nâŒ é”™è¯¯: {dataset_name}/{class_name}/k{k_shot}/{task}: {e}")
                    
                    pbar.update(1)
    
    pbar.close()
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    output_file = 'result/baseline_semantic_branch_auroc.csv'
    df.to_csv(output_file, index=False)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"æ€»è®¡: {len(results)}/{total_tasks} ä»»åŠ¡å®Œæˆ")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸ“Š Baseline Semanticåˆ†æ”¯ç»Ÿè®¡")
    print("=" * 80)
    
    for dataset_name in ['mvtec', 'visa']:
        for task in ['cls', 'seg']:
            subset = df[(df['dataset'] == dataset_name) & (df['task'] == task)]
            if len(subset) > 0:
                avg_auroc = subset['semantic_auroc'].mean()
                print(f"{dataset_name.upper()} {task.upper()}: å¹³å‡ {avg_auroc:.2f}% ({len(subset)}ä¸ªç±»åˆ«)")


if __name__ == '__main__':
    import os
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    main()
