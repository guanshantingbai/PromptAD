"""éªŒè¯è®­ç»ƒæ˜¯å¦çœŸæ­£å­¦åˆ°äº†ä¸œè¥¿"""
import torch
import sys
import os

# æ£€æŸ¥è®­ç»ƒå‰åçš„prototypeså˜åŒ–
class_name = "screw"
k_shot = 2

# 1. åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹çœ‹prototypesçš„åˆå§‹å€¼
print("=" * 80)
print("éªŒè¯è®­ç»ƒæ˜¯å¦æ”¹å˜äº†prototypes")
print("=" * 80)

# æ¨¡æ‹Ÿåˆå§‹åŒ–
from PromptAD.model import PromptAD
import argparse

kwargs = {
    'dataset': 'mvtec',
    'class_name': class_name,
    'k_shot': k_shot,
    'n_pro': 3,
    'n_pro_ab': 4,
    'resolution': 240,
    'out_size_h': 240,
    'out_size_w': 240,
    'device': 'cuda:0',
    'seed': 111,
    'backbone': 'ViT-B-16-plus-240',
    'pretrained_dataset': 'laion400m_e32',
    'n_ctx': 4,
    'n_ctx_ab': 4,
}

print(f"\nåˆå§‹åŒ–æ¨¡å‹ {class_name} (k={k_shot})...")
model_init = PromptAD(**kwargs)
model_init = model_init.to('cuda:0')
model_init.eval_mode()

# è·å–åˆå§‹prototypes
with torch.no_grad():
    normal_text_prompt, abnormal_text_prompt_handle, abnormal_text_prompt_learned = model_init.prompt_learner()
    initial_normal = model_init.encode_text_embedding(normal_text_prompt, model_init.tokenized_normal_prompts)
    abnormal_handle = model_init.encode_text_embedding(abnormal_text_prompt_handle, model_init.tokenized_abnormal_prompts_handle)
    abnormal_learned = model_init.encode_text_embedding(abnormal_text_prompt_learned, model_init.tokenized_abnormal_prompts_learned)
    initial_abnormal = torch.cat([abnormal_handle, abnormal_learned], dim=0)
    
    # Normalize
    initial_normal = initial_normal / initial_normal.norm(dim=-1, keepdim=True)
    initial_abnormal = initial_abnormal / initial_abnormal.norm(dim=-1, keepdim=True)

print(f"åˆå§‹ normal prototypes shape: {initial_normal.shape}")
print(f"åˆå§‹ normal prototypes[0, :5]: {initial_normal[0, :5]}")
print(f"åˆå§‹ abnormal prototypes shape: {initial_abnormal.shape}")
print(f"åˆå§‹ abnormal prototypes[0, :5]: {initial_abnormal[0, :5]}")

# 2. åŠ è½½è®­ç»ƒåçš„checkpoint
ckpt_path = f'result/prompt1_fixed/mvtec/k_{k_shot}/checkpoint/CLS-Seed_111-{class_name}-check_point.pt'
if not os.path.exists(ckpt_path):
    print(f"\nâŒ Checkpointä¸å­˜åœ¨: {ckpt_path}")
    sys.exit(1)

checkpoint = torch.load(ckpt_path, map_location='cpu')
trained_normal = checkpoint['normal_prototypes']
trained_abnormal = checkpoint['abnormal_prototypes']

print(f"\nè®­ç»ƒå normal prototypes shape: {trained_normal.shape}")
print(f"è®­ç»ƒå normal prototypes[0, :5]: {trained_normal[0, :5]}")
print(f"è®­ç»ƒå abnormal prototypes shape: {trained_abnormal.shape}")
print(f"è®­ç»ƒå abnormal prototypes[0, :5]: {trained_abnormal[0, :5]}")

# 3. æ¯”è¾ƒå·®å¼‚
initial_normal_cpu = initial_normal.cpu().float()
initial_abnormal_cpu = initial_abnormal.cpu().float()
trained_normal_float = trained_normal.float()
trained_abnormal_float = trained_abnormal.float()

normal_diff = torch.norm(initial_normal_cpu - trained_normal_float, dim=-1).mean()
abnormal_diff = torch.norm(initial_abnormal_cpu - trained_abnormal_float, dim=-1).mean()

print(f"\nğŸ“Š å˜åŒ–åˆ†æ:")
print(f"  Normal prototypeså¹³å‡L2è·ç¦»: {normal_diff:.6f}")
print(f"  Abnormal prototypeså¹³å‡L2è·ç¦»: {abnormal_diff:.6f}")

if normal_diff < 0.001 and abnormal_diff < 0.001:
    print(f"\n  âŒ ä¸¥é‡é—®é¢˜ï¼šprototypeså‡ ä¹æ²¡æœ‰å˜åŒ–ï¼è®­ç»ƒå¯èƒ½å¤±è´¥äº†")
elif normal_diff < 0.01 and abnormal_diff < 0.01:
    print(f"\n  âš ï¸  è­¦å‘Šï¼šprototypeså˜åŒ–å¾ˆå°ï¼Œè®­ç»ƒå¯èƒ½ä¸å……åˆ†")
else:
    print(f"\n  âœ… prototypeså‘ç”Ÿäº†æ˜æ˜¾å˜åŒ–ï¼Œè®­ç»ƒæ­£å¸¸")

# 4. æ£€æŸ¥æ˜¯å¦æ‰€æœ‰prototypeséƒ½ç›¸åŒï¼ˆæœªå­¦ä¹ çš„æ ‡å¿—ï¼‰
normal_std = trained_normal_float.std(dim=0).mean()
abnormal_std = trained_abnormal_float.std(dim=0).mean()

print(f"\n  Normal prototypesæ ‡å‡†å·®: {normal_std:.6f}")
print(f"  Abnormal prototypesæ ‡å‡†å·®: {abnormal_std:.6f}")

if normal_std < 0.001:
    print(f"  âŒ Normal prototypeså‡ ä¹ç›¸åŒï¼å¯èƒ½åˆå§‹åŒ–æœ‰é—®é¢˜")
if abnormal_std < 0.001:
    print(f"  âŒ Abnormal prototypeså‡ ä¹ç›¸åŒï¼å¯èƒ½åˆå§‹åŒ–æœ‰é—®é¢˜")
