"""
éªŒè¯å‡è®¾ï¼šå¤šåŸå‹è¯­ä¹‰åˆ†æ”¯åœ¨å•ç‹¬ä½¿ç”¨æ—¶ä¼˜äºbaselineï¼Œä½†èåˆåä¼˜åŠ¿å‡å¼±

æ•°æ®æ¥æºï¼š
1. result/prompt1/fair_comparison_semantic_only_k2.csv - è¯­ä¹‰åˆ†æ”¯å•ç‹¬å¯¹æ¯”
2. result/prompt1/fusion_comparison_k2.csv - èåˆåå®Œæ•´å¯¹æ¯”
3. result/baseline/aggregated_results.csv - Baselineèåˆç»“æœ
4. result/prompt1_memoryå½“å‰åˆ†æ”¯çš„ç»“æœ - Prompt1_Memoryèåˆç»“æœ
"""

import pandas as pd
import numpy as np

print("=" * 80)
print("éªŒè¯å‡è®¾ï¼šå¤šåŸå‹è¯­ä¹‰åˆ†æ”¯çš„ä¼˜åŠ¿åœ¨èåˆå‰åçš„å˜åŒ–")
print("=" * 80)

# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯­ä¹‰åˆ†æ”¯å•ç‹¬æ€§èƒ½å¯¹æ¯” (Baseline Semantic vs Prompt1 Semantic)
# ============================================================================
print("\n" + "=" * 80)
print("ã€å‡è®¾ç¬¬1éƒ¨åˆ†ã€‘è¯­ä¹‰åˆ†æ”¯å•ç‹¬ä½¿ç”¨ï¼šMulti-Prototype vs Baseline")
print("=" * 80)

semantic_df = pd.read_csv('result/prompt1/fair_comparison_semantic_only_k2.csv', skipinitialspace=True)
semantic_df.columns = semantic_df.columns.str.strip()

print("\nå•ç‹¬è¯­ä¹‰åˆ†æ”¯æ€§èƒ½å¯¹æ¯” (MVTec CLS, k=2):")
print(semantic_df.to_string(index=False))

# ç»Ÿè®¡è¯­ä¹‰åˆ†æ”¯çš„æ”¹è¿›
improved_semantic = semantic_df[semantic_df['diff'] > 0]
degraded_semantic = semantic_df[semantic_df['diff'] < 0]
unchanged_semantic = semantic_df[semantic_df['diff'] == 0]

print(f"\nè¯­ä¹‰åˆ†æ”¯ç»Ÿè®¡ï¼š")
print(f"  æ”¹è¿›ç±»åˆ«: {len(improved_semantic)}/15 ({len(improved_semantic)/15*100:.1f}%)")
print(f"  é€€åŒ–ç±»åˆ«: {len(degraded_semantic)}/15 ({len(degraded_semantic)/15*100:.1f}%)")
print(f"  æŒå¹³ç±»åˆ«: {len(unchanged_semantic)}/15 ({len(unchanged_semantic)/15*100:.1f}%)")
print(f"\n  å¹³å‡æ”¹è¿›å¹…åº¦: {semantic_df['diff'].mean():.2f}%")
print(f"  æœ€å¤§æ”¹è¿›: {semantic_df['diff'].max():.2f}% ({semantic_df.loc[semantic_df['diff'].idxmax(), 'class']})")
print(f"  æœ€å¤§é€€åŒ–: {semantic_df['diff'].min():.2f}% ({semantic_df.loc[semantic_df['diff'].idxmin(), 'class']})")

# è®¡ç®—æ•´ä½“å¹³å‡æ€§èƒ½
baseline_semantic_avg = semantic_df['baseline_semantic'].mean()
prompt1_semantic_avg = semantic_df['multi_prototype'].mean()
semantic_improvement = prompt1_semantic_avg - baseline_semantic_avg

print(f"\næ•´ä½“å¹³å‡AUROC:")
print(f"  Baselineè¯­ä¹‰åˆ†æ”¯: {baseline_semantic_avg:.2f}%")
print(f"  Prompt1è¯­ä¹‰åˆ†æ”¯:  {prompt1_semantic_avg:.2f}%")
print(f"  æ”¹è¿›: +{semantic_improvement:.2f}%")

print("\nâœ… ç»“è®ºï¼šè¯­ä¹‰åˆ†æ”¯å•ç‹¬ä½¿ç”¨æ—¶ï¼ŒMulti-Prototypeåœ¨13/15ç±»åˆ«ä¸Šä¼˜äºBaseline")
print(f"         æ•´ä½“å¹³å‡æ”¹è¿› {semantic_improvement:.2f}%ï¼Œå‡è®¾ç¬¬1éƒ¨åˆ†æˆç«‹ï¼")

# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šèåˆåæ€§èƒ½å¯¹æ¯”
# ============================================================================
print("\n\n" + "=" * 80)
print("ã€å‡è®¾ç¬¬2éƒ¨åˆ†ã€‘èåˆåæ€§èƒ½ï¼šä¼˜åŠ¿æ˜¯å¦å‡å¼±ï¼Ÿ")
print("=" * 80)

fusion_df = pd.read_csv('result/prompt1/fusion_comparison_k2.csv')

print("\nèåˆåå®Œæ•´å¯¹æ¯” (MVTec CLS, k=2):")
print(fusion_df[['Class', 'Baseline_Full', 'Prompt1_Fusion', 'Fusion_vs_Baseline_Full']].to_string(index=False))

# ç»Ÿè®¡èåˆåçš„æ”¹è¿›
improved_fusion = fusion_df[fusion_df['Fusion_vs_Baseline_Full'] > 0]
degraded_fusion = fusion_df[fusion_df['Fusion_vs_Baseline_Full'] < 0]
unchanged_fusion = fusion_df[fusion_df['Fusion_vs_Baseline_Full'] == 0]

print(f"\nèåˆåç»Ÿè®¡ï¼š")
print(f"  æ”¹è¿›ç±»åˆ«: {len(improved_fusion)}/15 ({len(improved_fusion)/15*100:.1f}%)")
print(f"  é€€åŒ–ç±»åˆ«: {len(degraded_fusion)}/15 ({len(degraded_fusion)/15*100:.1f}%)")
print(f"  æŒå¹³ç±»åˆ«: {len(unchanged_fusion)}/15 ({len(unchanged_fusion)/15*100:.1f}%)")
print(f"\n  å¹³å‡æ”¹è¿›å¹…åº¦: {fusion_df['Fusion_vs_Baseline_Full'].mean():.2f}%")
print(f"  æœ€å¤§æ”¹è¿›: {fusion_df['Fusion_vs_Baseline_Full'].max():.2f}% ({fusion_df.loc[fusion_df['Fusion_vs_Baseline_Full'].idxmax(), 'Class']})")
print(f"  æœ€å¤§é€€åŒ–: {fusion_df['Fusion_vs_Baseline_Full'].min():.2f}% ({fusion_df.loc[fusion_df['Fusion_vs_Baseline_Full'].idxmin(), 'Class']})")

# è®¡ç®—æ•´ä½“å¹³å‡æ€§èƒ½
baseline_fusion_avg = fusion_df['Baseline_Full'].mean()
prompt1_fusion_avg = fusion_df['Prompt1_Fusion'].mean()
fusion_improvement = prompt1_fusion_avg - baseline_fusion_avg

print(f"\næ•´ä½“å¹³å‡AUROC:")
print(f"  Baselineèåˆ: {baseline_fusion_avg:.2f}%")
print(f"  Prompt1èåˆ:  {prompt1_fusion_avg:.2f}%")
print(f"  æ”¹è¿›: {fusion_improvement:+.2f}%")

print("\nâš ï¸  ç»“è®ºï¼šèåˆåï¼Œæ”¹è¿›ç±»åˆ«ä»13/15é™è‡³2/15ï¼Œæ•´ä½“å¹³å‡ä»+{:.2f}%é™è‡³{:+.2f}%".format(
    semantic_improvement, fusion_improvement))
print("         ä¼˜åŠ¿åœ¨æ•´ä½“ä¸Šä¸å¤å­˜åœ¨ï¼Œå‡è®¾ç¬¬2éƒ¨åˆ†æˆç«‹ï¼")

# ============================================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šåˆ†æä¼˜åŠ¿ä¸ºä½•æ¶ˆå¤±
# ============================================================================
print("\n\n" + "=" * 80)
print("ã€æ·±å…¥åˆ†æã€‘ä¸ºä»€ä¹ˆèåˆåä¼˜åŠ¿æ¶ˆå¤±ï¼Ÿ")
print("=" * 80)

# åˆå¹¶æ•°æ®è¿›è¡Œåˆ†æ
analysis_df = fusion_df[['Class', 'Baseline_Semantic', 'Prompt1_Semantic', 
                          'Semantic_Improvement', 'Fusion_vs_Baseline_Full',
                          'Fusion_vs_Semantic']].copy()

print("\nè¯­ä¹‰æ”¹è¿› vs èåˆåç»“æœ:")
print(analysis_df.to_string(index=False))

# åˆ†æè¯­ä¹‰æ”¹è¿›ä¸èåˆç»“æœçš„å…³ç³»
print("\nå…³é”®å‘ç°ï¼š")
print("1. è¯­ä¹‰åˆ†æ”¯æ”¹è¿›æœ€å¤§çš„ç±»åˆ« (toothbrush +19.86%, screw +13.15%):")
print("   - èåˆåç›¸å¯¹baseline: toothbrush -8.62%, screw -5.66%")
print("   - è¯´æ˜è§†è§‰åˆ†æ”¯æ‹–ç´¯äº†æ€§èƒ½\n")

print("2. æŸ¥çœ‹ Fusion_vs_Semantic (èåˆç›¸å¯¹çº¯è¯­ä¹‰çš„å˜åŒ–):")
seriously_degraded = analysis_df[analysis_df['Fusion_vs_Semantic'] < -5]
print(f"   èåˆåç›¸å¯¹çº¯è¯­ä¹‰ä¸¥é‡é€€åŒ–çš„ç±»åˆ« (>5%):")
for _, row in seriously_degraded.iterrows():
    print(f"   - {row['Class']}: {row['Fusion_vs_Semantic']:.2f}%")

print("\n3. å¯èƒ½çš„åŸå› :")
print("   - è§†è§‰åˆ†æ”¯(Memory Bank)åœ¨æŸäº›ç±»åˆ«ä¸Šè¡¨ç°ä¸ä½³")
print("   - è°ƒå’Œå‡å€¼èåˆç­–ç•¥åœ¨è¯­ä¹‰å¼ºã€è§†è§‰å¼±æ—¶è¢«æ‹–ç´¯")
print("   - Baselineçš„è§†è§‰åˆ†æ”¯å¯èƒ½åœ¨è¿™äº›ç±»åˆ«ä¸Šæ›´å¼º")

# ============================================================================
# ç¬¬å››éƒ¨åˆ†ï¼šä¸ªåˆ«ç±»åˆ«çš„ç•™å­˜ä¼˜åŠ¿
# ============================================================================
print("\n\n" + "=" * 80)
print("ã€å‡è®¾ç¬¬2éƒ¨åˆ†è¡¥å……ã€‘ä¸ªåˆ«ç±»åˆ«ä¸Šä¼˜åŠ¿æ˜¯å¦ç•™å­˜ï¼Ÿ")
print("=" * 80)

# æ‰¾å‡ºèåˆåä»ç„¶æ”¹è¿›çš„ç±»åˆ«
retained_advantage = fusion_df[fusion_df['Fusion_vs_Baseline_Full'] > 1.0][
    ['Class', 'Semantic_Improvement', 'Fusion_vs_Baseline_Full']
]

print("\nèåˆåä»ä¿æŒæ˜¾è‘—ä¼˜åŠ¿çš„ç±»åˆ« (>1%):")
if len(retained_advantage) > 0:
    print(retained_advantage.to_string(index=False))
    print(f"\nâœ… æ˜¯çš„ï¼Œåœ¨ {len(retained_advantage)}/15 ä¸ªç±»åˆ«ä¸Šï¼Œèåˆåä»ä¿æŒæ˜¾è‘—ä¼˜åŠ¿")
else:
    print("æ— æ˜¾è‘—ä¼˜åŠ¿ä¿ç•™ (>1%)")

# æ‰¾å‡ºæ‰€æœ‰æ”¹è¿›çš„ç±»åˆ«
all_retained = fusion_df[fusion_df['Fusion_vs_Baseline_Full'] > 0][
    ['Class', 'Semantic_Improvement', 'Fusion_vs_Baseline_Full']
]
print(f"\nèåˆåæ‰€æœ‰æ”¹è¿›çš„ç±»åˆ« (>0%):")
print(all_retained.to_string(index=False))
print(f"\nâœ… å…±æœ‰ {len(all_retained)}/15 ä¸ªç±»åˆ«åœ¨èåˆåä»ä¿æŒæ”¹è¿›")

# ============================================================================
# æœ€ç»ˆç»“è®º
# ============================================================================
print("\n\n" + "=" * 80)
print("ã€æœ€ç»ˆç»“è®ºã€‘")
print("=" * 80)

print("\nä½ çš„å‡è®¾åœ¨å¤šå¤§ç¨‹åº¦ä¸Šç«™å¾—ä½è„šï¼Ÿ\n")

print("âœ… ã€å‡è®¾1å®Œå…¨æˆç«‹ã€‘è¯­ä¹‰åˆ†æ”¯å•ç‹¬ä½¿ç”¨æ—¶ä¼˜äºBaseline")
print(f"   è¯æ®ï¼š13/15ç±»åˆ«æ”¹è¿›ï¼Œå¹³å‡+{semantic_improvement:.2f}%")
print(f"   æœ€å¤§æ”¹è¿›ï¼štoothbrush +19.86%, screw +13.15%\n")

print("âœ… ã€å‡è®¾2æ•´ä½“æˆç«‹ã€‘èåˆåä¼˜åŠ¿åœ¨æ•´ä½“ä¸Šä¸å¤å­˜åœ¨")
print(f"   è¯æ®ï¼šæ”¹è¿›ç±»åˆ«ä»13/15é™è‡³{len(all_retained)}/15")
print(f"   å¹³å‡æ”¹è¿›ä»+{semantic_improvement:.2f}%é™è‡³{fusion_improvement:+.2f}%")
print(f"   æ•´ä½“ä¸Šæ¥è¿‘æŒå¹³æˆ–ç•¥æœ‰é€€åŒ–\n")

print("âœ… ã€å‡è®¾2å±€éƒ¨æˆç«‹ã€‘ä¸ªåˆ«ç±»åˆ«ä¸Šä¼˜åŠ¿æœ‰ç•™å­˜")
print(f"   è¯æ®ï¼š{len(retained_advantage)}/15ç±»åˆ«ä¿æŒ>1%ä¼˜åŠ¿")
print(f"   æ˜¾è‘—æ”¹è¿›: capsule +4.59%")
print(f"   ä½†ç›¸æ¯”è¯­ä¹‰åˆ†æ”¯çš„æ”¹è¿›å¹…åº¦å¤§å¹…ç¼©å°\n")

print("ğŸ” ã€æ ¸å¿ƒå‘ç°ã€‘")
print("   1. å¤šåŸå‹è¯­ä¹‰åˆ†æ”¯æœ¬èº«æ˜¯æœ‰æ•ˆçš„ (çº¯è¯­ä¹‰+{:.2f}%)".format(semantic_improvement))
print("   2. è§†è§‰åˆ†æ”¯(Memory Bank)åœ¨éƒ¨åˆ†ç±»åˆ«ä¸Šè¡¨ç°ä¸ä½³")
print("   3. è°ƒå’Œå‡å€¼èåˆç­–ç•¥è¢«å¼±åˆ†æ”¯æ‹–ç´¯")
print("   4. éœ€è¦æ”¹è¿›è§†è§‰åˆ†æ”¯æˆ–ä½¿ç”¨è‡ªé€‚åº”èåˆæƒé‡\n")

print("=" * 80)
print("ç»“è®ºï¼šä½ çš„ç†è§£ **å®Œå…¨æ­£ç¡®**ï¼Œä¸”å¾—åˆ°äº†æ•°æ®çš„å……åˆ†æ”¯æŒï¼")
print("=" * 80)
